{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "from Assistant import AssistantOpenAI\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from git import Repo\n",
    "\n",
    "import numpy as np\n",
    "#from collections import deque, namedtuple\n",
    "\n",
    "# For visualization\n",
    "import gymnasium.wrappers.record_video as record_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 200\n",
    "ENV_NAME = 'LunarLander-v2'\n",
    "ARCLABKEY_OPENAI = \"sk-proj-DvHDR3hpgbm2r3kCA9jKT3BlbkFJL57ABXkfaWAIYKBxdhM6\"\n",
    "ARCLABKEY_OPENAI = \"sk-proj-GvaDXazpibWA2M1I5Pu2T3BlbkFJxDuKlr9AcoVG98ctJZ7Q\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function calling.\n",
    "\n",
    "Función encargada de almacenar el código generado mediante la opción de function calling del asistente de OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_code_in_file(code, filename):\n",
    "    \"\"\" Store code in a file\n",
    "    \n",
    "    Args:\n",
    "        code: str: code to store\n",
    "        filename: str: filename to store code in\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(code)\n",
    "        \n",
    "store_code_in_file_schema = {\n",
    "    \"name\": \"store_code_in_file\",\n",
    "    \"description\": \"Store code in a file\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"code\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The Python code to store.\"\n",
    "            },\n",
    "            \"filename\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The filename to store the code in.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"code\", \"filename\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "TOOLS = [{\"type\": \"function\", \"function\": store_code_in_file_schema}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entorno Lunnar Lander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_initial_code = \"\"\"\n",
    "import random\n",
    "\n",
    "def act(observation):\n",
    "    '''\n",
    "    The function that codifies the action to be taken in each instant of time.\n",
    "\n",
    "    Args:\n",
    "        observation (numpy.array):\n",
    "            \"description\": \"The state of the environment after the action is taken.\",\n",
    "            \"positions\": {  \n",
    "                \"0\": \"X position\",\n",
    "                \"1\": \"Y position\",\n",
    "                \"2\": \"X velocity\",\n",
    "                \"3\": \"Y velocity\",\n",
    "                \"4\": \"Angle\",\n",
    "                \"5\": \"Angular velocity\",\n",
    "                \"6\": \"Left contact sensor\",\n",
    "                \"7\": \"Right contact sensor\"\n",
    "            },\n",
    "            \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\n",
    "            \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\n",
    "\n",
    "    Returns:\n",
    "        Integer  : The action to be taken.\n",
    "    '''\n",
    "    return random.randint(0, 3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapeador de logs a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_description = {\n",
    "    \"description\": \"Log data for each step of the spacecraft landing environment.\",\n",
    "    \"landing attempt\": {\n",
    "        \"type\": \"integer\",\n",
    "        \"description\": \"The episode number.\"\n",
    "    },\n",
    "    \"logs\": {\n",
    "        \"instant\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The instant within the landing attempt where the current log is taken.\"\n",
    "        },\n",
    "        \"action\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The possible actions taken.\",\n",
    "            \"options\": {\n",
    "                1 : \"Switch off engines\",\n",
    "                2 : \"Push left engine\",\n",
    "                3 : \"Push both engines (upwards)\",\n",
    "                4 : \"Push right engine\"\n",
    "            }\n",
    "        },  \n",
    "        \"current status\": {\n",
    "            \"type\": \"array\",\n",
    "            \"description\": \"The state of the environment after the action is taken.\",\n",
    "            \"positions\": {  \n",
    "                \"0\": \"X position\",\n",
    "                \"1\": \"Y position\",\n",
    "                \"2\": \"X velocity\",\n",
    "                \"3\": \"Y velocity\",\n",
    "                \"4\": \"Angle\",\n",
    "                \"5\": \"Angular velocity\",\n",
    "                \"6\": \"Left contact sensor\",\n",
    "                \"7\": \"Right contact sensor\"\n",
    "            },\n",
    "            \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\n",
    "            \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1] \n",
    "        }, \n",
    "        \"score\": {\n",
    "            \"type\": \"number\",\n",
    "            \"description\": \"The score received for the action.\"\n",
    "        },  \n",
    "        \"completed\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"Whether the landing event has ended (landing or accident).\"\n",
    "        }\n",
    "    },\n",
    "    \"total score\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"The total score received for the landing attempt.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_step_data(instant, action, next_state, reward, terminated):\n",
    "    \"\"\" Format the step data into a JSON string\n",
    "    \n",
    "    Args:\n",
    "        instant: int: the instant within the landing attempt where the current log is taken\n",
    "        action: int: the action taken\n",
    "        next_state: np.array: the next state of the environment\n",
    "        reward: float: the reward received\n",
    "        terminated: bool: whether the landing event has ended\n",
    "        \n",
    "    Returns:\n",
    "        str: the step data formatted as a JSON string\n",
    "    \"\"\"\n",
    "    # Convertir el array numpy a una lista\n",
    "    next_state_list = next_state.tolist()\n",
    "\n",
    "    # Redondear los elementos de la lista a 4 decimales\n",
    "    next_state_list_rounded = [round(x, 3) for x in next_state_list]\n",
    "\n",
    "    step_data = {\n",
    "        'instant': instant,\n",
    "        'action' : int(action),\n",
    "        'current status': next_state_list_rounded,  # Convert numpy array to list\n",
    "        'score': round(reward, 3),\n",
    "        'completed': terminated,\n",
    "        #'truncated': truncated\n",
    "        #'info': info\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a JSON string\n",
    "    step_data_json = json.dumps(step_data)\n",
    "\n",
    "    return step_data_json\n",
    "\n",
    "\n",
    "def format_episode_logs(logs, episode, total_score):\n",
    "    \"\"\" Format the logs into a JSON string\n",
    "    \n",
    "    Args:\n",
    "        logs: list: the logs for each step of the environment\n",
    "        episode: int: the episode number\n",
    "        \n",
    "    Returns:\n",
    "        str: the logs formatted as a JSON string\n",
    "    \"\"\"\n",
    "    logs_data = {\n",
    "        'landing attempt': episode,\n",
    "        'logs': logs,\n",
    "        'total score': total_score\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a JSON string\n",
    "    logs_json = json.dumps(logs_data)\n",
    "\n",
    "    return logs_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_changes(repo_path, commit_message):\n",
    "    \"\"\" Commit changes to the repository.\n",
    "\n",
    "    Args:\n",
    "        repo_path (str): Path to the repository.\n",
    "        commit_message (str): The commit message.\n",
    "    \"\"\"\n",
    "    repo = Repo(repo_path)\n",
    "    repo.git.add(update=True)\n",
    "    repo.index.commit(commit_message)\n",
    "    origin = repo.remote(name='origin')\n",
    "    origin.push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código encargado de ejecutar los eventos en el entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Action\n",
    "\n",
    "def lunar_lander(max_t=1000, n_games=1, display=False, seed=38, agent=None, recoder=False, video_filename='video/video.mp4'):\n",
    "    \"\"\" Run the Lunar Lander environment\n",
    "    \n",
    "    Args:\n",
    "        max_t: int: the maximum number of timesteps\n",
    "        n_games: int: the number of games to play\n",
    "        display: bool: whether to display the environment\n",
    "        seed: int: the seed for the environment\n",
    "        agent: object: the agent to use\n",
    "        recoder: bool: whether to record the video\n",
    "        video_filename: str: the filename for the video\n",
    "        \n",
    "    Returns:\n",
    "        str: the logs for the landing attempts\n",
    "    \"\"\"\n",
    "    \n",
    "    # Incluimos la opción del entorno gráfico y la de grabación.\n",
    "    if display:\n",
    "        env = gym.make(ENV_NAME, render_mode='human')\n",
    "        if recoder:\n",
    "            env = gym.make(ENV_NAME, render_mode='rgb_array')\n",
    "            env.reset() \n",
    "            video_recorder = record_video.RecordVideo(env, video_filename)\n",
    "    else:\n",
    "        env = gym.make(ENV_NAME)\n",
    "\n",
    "    # Bucle principal de ejecución de los episodios.\n",
    "    logs = []\n",
    "    for episode in range(1, n_games+1):\n",
    "        state = env.reset(seed=seed) # Set a seed for the environment\n",
    "        state = state[0] # Eliminamos el diccionario vacio y dejamos unicamente el estado de 8 elementos.\n",
    "        score = 0\n",
    "        instant = 0\n",
    "        episode_actions = []\n",
    "        if recoder: # En caso de que se quiera grabar el video, se inicia el grabador.\n",
    "            video_recorder.start_video_recorder()\n",
    "            \n",
    "        for i in range(max_t): # Bucle de ejecución de los instantes de tiempo.\n",
    "            \n",
    "            # Seleccionamos el método de elegir la acción (agente exitoso o método de decisión del asistente)\n",
    "            if agent: \n",
    "                action = agent.act(state)\n",
    "            else:\n",
    "                action = Action.act(state)\n",
    "            \n",
    "            # Avanzamos un instante de tiempo en el entorno en función de si se quiere grabar el video o no.\n",
    "            if recoder:\n",
    "                next_state, reward, terminated, truncated, info = video_recorder.step(action)\n",
    "            else:\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "            # Formateamos los datos del instante de tiempo y los alcenamos.\n",
    "            json_logs = format_step_data(instant, action, next_state, reward, terminated)\n",
    "            score += reward\n",
    "            instant += 1\n",
    "            if len(episode_actions) == 0 or len(episode_actions) % 2 == 0 or terminated:\n",
    "                logs.append(json_logs)\n",
    "            episode_actions.append(action)\n",
    "            state = next_state\n",
    "            if terminated: # Condición de salida del bucle, si el episodio ha terminado.\n",
    "                break\n",
    "        json_episode_logs = format_episode_logs(logs, episode, score) \n",
    "        \n",
    "        print(f\"Número de instantes: {instant+1}. Tamaño de logs: {len(logs)}\")\n",
    "        print('episode ', episode, 'score %.3f' % float(score), 'avg score %.3f' % (float(score) / instant))\n",
    "        \n",
    "    if recoder:\n",
    "        video_recorder.close()\n",
    "    else:\n",
    "        env.close()\n",
    "        \n",
    "    return json_episode_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs del código inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de instantes: 97. Tamaño de logs: 49\n",
      "episode  1 score -57.134 avg score -0.595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"landing attempt\": 1, \"logs\": [\"{\\\\\"instant\\\\\": 0, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.008, 1.417, 0.39, 0.131, -0.01, -0.123, 0.0, 0.0], \\\\\"score\\\\\": -0.871, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 2, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.016, 1.421, 0.412, 0.077, -0.03, -0.211, 0.0, 0.0], \\\\\"score\\\\\": -1.707, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 4, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.024, 1.423, 0.431, 0.023, -0.056, -0.286, 0.0, 0.0], \\\\\"score\\\\\": -2.308, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 6, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.032, 1.422, 0.45, -0.032, -0.091, -0.364, 0.0, 0.0], \\\\\"score\\\\\": -2.782, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 8, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.041, 1.419, 0.448, -0.085, -0.128, -0.356, 0.0, 0.0], \\\\\"score\\\\\": -0.974, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 10, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.049, 1.414, 0.43, -0.137, -0.158, -0.283, 0.0, 0.0], \\\\\"score\\\\\": -1.074, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 12, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.058, 1.406, 0.413, -0.188, -0.182, -0.21, 0.0, 0.0], \\\\\"score\\\\\": -0.698, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 14, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.065, 1.396, 0.394, -0.239, -0.197, -0.135, 0.0, 0.0], \\\\\"score\\\\\": -0.544, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 16, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.073, 1.383, 0.374, -0.291, -0.205, -0.053, 0.0, 0.0], \\\\\"score\\\\\": -0.26, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 18, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.08, 1.368, 0.352, -0.342, -0.203, 0.038, 0.0, 0.0], \\\\\"score\\\\\": 0.007, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 20, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.087, 1.351, 0.331, -0.392, -0.193, 0.125, 0.0, 0.0], \\\\\"score\\\\\": 0.353, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 22, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.093, 1.332, 0.312, -0.443, -0.174, 0.205, 0.0, 0.0], \\\\\"score\\\\\": 0.36, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 24, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.1, 1.31, 0.293, -0.495, -0.148, 0.278, 0.0, 0.0], \\\\\"score\\\\\": 0.627, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 26, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.106, 1.286, 0.273, -0.547, -0.114, 0.358, 0.0, 0.0], \\\\\"score\\\\\": 1.144, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 28, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.111, 1.26, 0.26, -0.57, -0.074, 0.397, 0.0, 0.0], \\\\\"score\\\\\": 3.318, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 30, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.117, 1.236, 0.269, -0.538, -0.035, 0.398, 0.0, 0.0], \\\\\"score\\\\\": 3.982, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 32, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.122, 1.212, 0.258, -0.514, 0.004, 0.384, 0.0, 0.0], \\\\\"score\\\\\": 3.709, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 34, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.128, 1.189, 0.253, -0.51, 0.041, 0.38, 0.0, 0.0], \\\\\"score\\\\\": -1.385, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 36, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.133, 1.167, 0.254, -0.475, 0.08, 0.389, 0.0, 0.0], \\\\\"score\\\\\": 2.321, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 38, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.139, 1.145, 0.27, -0.501, 0.118, 0.358, 0.0, 0.0], \\\\\"score\\\\\": -3.501, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 40, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.145, 1.121, 0.288, -0.553, 0.149, 0.282, 0.0, 0.0], \\\\\"score\\\\\": -3.057, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 42, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.151, 1.094, 0.309, -0.604, 0.17, 0.196, 0.0, 0.0], \\\\\"score\\\\\": -2.438, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 44, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.158, 1.065, 0.333, -0.655, 0.182, 0.1, 0.0, 0.0], \\\\\"score\\\\\": -1.843, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 46, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.165, 1.034, 0.35, -0.706, 0.187, 0.027, 0.0, 0.0], \\\\\"score\\\\\": -1.343, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 48, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.172, 1.001, 0.372, -0.756, 0.183, -0.064, 0.0, 0.0], \\\\\"score\\\\\": -0.789, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 50, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.18, 0.965, 0.391, -0.807, 0.17, -0.141, 0.0, 0.0], \\\\\"score\\\\\": -0.222, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 52, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.188, 0.927, 0.408, -0.859, 0.151, -0.209, 0.0, 0.0], \\\\\"score\\\\\": 0.085, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 54, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.196, 0.886, 0.428, -0.909, 0.124, -0.293, 0.0, 0.0], \\\\\"score\\\\\": 0.6, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 56, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.204, 0.844, 0.448, -0.961, 0.089, -0.373, 0.0, 0.0], \\\\\"score\\\\\": 1.15, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 58, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.212, 0.802, 0.411, -0.92, 0.049, -0.398, 0.0, 0.0], \\\\\"score\\\\\": 4.814, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 60, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.22, 0.762, 0.404, -0.896, 0.01, -0.4, 0.0, 0.0], \\\\\"score\\\\\": 3.758, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 62, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.228, 0.723, 0.406, -0.851, -0.031, -0.397, 0.0, 0.0], \\\\\"score\\\\\": 1.185, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 64, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.236, 0.685, 0.425, -0.838, -0.069, -0.383, 0.0, 0.0], \\\\\"score\\\\\": -0.001, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 66, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.244, 0.65, 0.443, -0.773, -0.107, -0.379, 0.0, 0.0], \\\\\"score\\\\\": 1.484, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 68, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.252, 0.613, 0.424, -0.826, -0.14, -0.301, 0.0, 0.0], \\\\\"score\\\\\": -1.738, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 70, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.26, 0.574, 0.404, -0.878, -0.164, -0.223, 0.0, 0.0], \\\\\"score\\\\\": -1.559, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 72, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.268, 0.533, 0.385, -0.929, -0.18, -0.143, 0.0, 0.0], \\\\\"score\\\\\": -0.924, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 74, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.275, 0.489, 0.365, -0.981, -0.189, -0.064, 0.0, 0.0], \\\\\"score\\\\\": -0.536, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 76, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.282, 0.444, 0.343, -1.031, -0.189, 0.027, 0.0, 0.0], \\\\\"score\\\\\": -0.157, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 78, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.289, 0.395, 0.324, -1.082, -0.18, 0.107, 0.0, 0.0], \\\\\"score\\\\\": 0.145, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 80, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.295, 0.345, 0.307, -1.133, -0.164, 0.175, 0.0, 0.0], \\\\\"score\\\\\": 0.363, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 82, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.301, 0.292, 0.289, -1.186, -0.142, 0.247, 0.0, 0.0], \\\\\"score\\\\\": 0.642, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 84, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.307, 0.237, 0.272, -1.237, -0.112, 0.316, 0.0, 0.0], \\\\\"score\\\\\": 0.809, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 86, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.313, 0.18, 0.276, -1.265, -0.076, 0.359, 0.0, 0.0], \\\\\"score\\\\\": 2.315, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 88, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.319, 0.124, 0.278, -1.216, -0.041, 0.352, 0.0, 0.0], \\\\\"score\\\\\": 6.353, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 90, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.325, 0.072, 0.279, -1.165, -0.006, 0.348, 0.0, 0.0], \\\\\"score\\\\\": 3.759, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 92, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.331, 0.02, 0.266, -1.131, 0.029, 0.335, 0.0, 0.0], \\\\\"score\\\\\": -0.539, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 94, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.336, -0.029, 0.273, -1.081, 0.043, -0.044, 1.0, 1.0], \\\\\"score\\\\\": 14.213, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 95, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.338, -0.05, 0.354, -0.612, 0.009, -3.432, 1.0, 1.0], \\\\\"score\\\\\": -100, \\\\\"completed\\\\\": true}\"], \"total score\": -57.13390452568175}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_logs = lunar_lander(n_games=1, display=True)\n",
    "initial_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs exitosos\n",
    "Utilizar otras semillas para que no memorice el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de instantes: 294. Tamaño de logs: 147\n",
      "episode  1 score 250.956 avg score 0.857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"landing attempt\": 1, \"logs\": [\"{\\\\\"instant\\\\\": 0, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.004, 1.425, 0.22, 0.295, -0.003, -0.004, 0.0, 0.0], \\\\\"score\\\\\": 2.08, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 2, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.009, 1.436, 0.22, 0.242, -0.003, -0.004, 0.0, 0.0], \\\\\"score\\\\\": 1.453, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 4, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.013, 1.445, 0.22, 0.188, -0.004, -0.004, 0.0, 0.0], \\\\\"score\\\\\": 1.354, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 6, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.018, 1.452, 0.211, 0.135, -0.002, 0.032, 0.0, 0.0], \\\\\"score\\\\\": 2.092, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 8, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.022, 1.456, 0.211, 0.081, 0.001, 0.032, 0.0, 0.0], \\\\\"score\\\\\": 0.866, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 10, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.026, 1.458, 0.211, 0.028, 0.004, 0.032, 0.0, 0.0], \\\\\"score\\\\\": 0.283, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 12, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.03, 1.458, 0.202, -0.026, 0.011, 0.068, 0.0, 0.0], \\\\\"score\\\\\": -0.45, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 14, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.034, 1.455, 0.202, -0.079, 0.018, 0.068, 0.0, 0.0], \\\\\"score\\\\\": -0.991, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 16, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.038, 1.449, 0.202, -0.132, 0.025, 0.068, 0.0, 0.0], \\\\\"score\\\\\": -1.4, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 18, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.043, 1.441, 0.213, -0.185, 0.029, 0.025, 0.0, 0.0], \\\\\"score\\\\\": -2.239, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 20, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.047, 1.431, 0.215, -0.238, 0.033, 0.018, 0.0, 0.0], \\\\\"score\\\\\": -2.229, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 22, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.051, 1.419, 0.213, -0.292, 0.038, 0.026, 0.0, 0.0], \\\\\"score\\\\\": -2.201, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 24, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.056, 1.404, 0.214, -0.346, 0.038, 0.02, 0.0, 0.0], \\\\\"score\\\\\": -1.145, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 26, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.06, 1.386, 0.213, -0.4, 0.038, 0.025, 0.0, 0.0], \\\\\"score\\\\\": -1.152, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 28, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.064, 1.37, 0.195, -0.357, 0.04, 0.013, 0.0, 0.0], \\\\\"score\\\\\": 4.223, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 30, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.068, 1.352, 0.195, -0.411, 0.04, 0.014, 0.0, 0.0], \\\\\"score\\\\\": -1.205, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 32, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.072, 1.335, 0.195, -0.361, 0.042, 0.021, 0.0, 0.0], \\\\\"score\\\\\": 3.131, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 34, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.076, 1.317, 0.191, -0.415, 0.043, 0.036, 0.0, 0.0], \\\\\"score\\\\\": -1.229, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 36, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.08, 1.3, 0.184, -0.38, 0.047, 0.034, 0.0, 0.0], \\\\\"score\\\\\": 0.83, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 38, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.083, 1.283, 0.182, -0.359, 0.051, 0.037, 0.0, 0.0], \\\\\"score\\\\\": 2.18, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 40, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.087, 1.266, 0.175, -0.373, 0.049, -0.019, 0.0, 0.0], \\\\\"score\\\\\": 2.543, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 42, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.09, 1.249, 0.169, -0.361, 0.051, 0.018, 0.0, 0.0], \\\\\"score\\\\\": 3.903, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 44, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.094, 1.231, 0.173, -0.414, 0.049, 0.005, 0.0, 0.0], \\\\\"score\\\\\": -1.216, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 46, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.097, 1.213, 0.173, -0.395, 0.05, 0.01, 0.0, 0.0], \\\\\"score\\\\\": 0.2, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 48, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.1, 1.196, 0.16, -0.367, 0.05, 0.003, 0.0, 0.0], \\\\\"score\\\\\": 1.501, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 50, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.104, 1.179, 0.155, -0.362, 0.054, 0.043, 0.0, 0.0], \\\\\"score\\\\\": 3.148, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 52, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.107, 1.162, 0.166, -0.364, 0.054, 0.006, 0.0, 0.0], \\\\\"score\\\\\": 2.62, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 54, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.11, 1.145, 0.154, -0.393, 0.059, 0.047, 0.0, 0.0], \\\\\"score\\\\\": 0.279, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 56, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.113, 1.128, 0.138, -0.38, 0.063, 0.038, 0.0, 0.0], \\\\\"score\\\\\": 0.473, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 58, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.116, 1.111, 0.14, -0.352, 0.068, 0.047, 0.0, 0.0], \\\\\"score\\\\\": 2.786, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 60, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.119, 1.095, 0.14, -0.337, 0.069, 0.017, 0.0, 0.0], \\\\\"score\\\\\": 4.455, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 62, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.121, 1.078, 0.138, -0.39, 0.07, 0.025, 0.0, 0.0], \\\\\"score\\\\\": -1.483, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 64, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.124, 1.062, 0.142, -0.376, 0.071, -0.008, 0.0, 0.0], \\\\\"score\\\\\": -1.935, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 66, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.127, 1.046, 0.117, -0.348, 0.069, -0.023, 0.0, 0.0], \\\\\"score\\\\\": 2.82, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 68, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.129, 1.029, 0.108, -0.371, 0.07, 0.011, 0.0, 0.0], \\\\\"score\\\\\": 0.804, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 70, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.131, 1.013, 0.113, -0.359, 0.072, 0.022, 0.0, 0.0], \\\\\"score\\\\\": 1.278, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 72, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.134, 0.995, 0.135, -0.383, 0.071, -0.009, 0.0, 0.0], \\\\\"score\\\\\": 0.435, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 74, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.136, 0.979, 0.106, -0.354, 0.068, -0.029, 0.0, 0.0], \\\\\"score\\\\\": 3.022, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 76, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.138, 0.962, 0.109, -0.369, 0.069, 0.02, 0.0, 0.0], \\\\\"score\\\\\": 1.255, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 78, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.14, 0.946, 0.118, -0.35, 0.072, 0.035, 0.0, 0.0], \\\\\"score\\\\\": 0.819, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 80, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.142, 0.93, 0.111, -0.372, 0.071, -0.03, 0.0, 0.0], \\\\\"score\\\\\": -1.922, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 82, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.145, 0.914, 0.104, -0.36, 0.071, 0.01, 0.0, 0.0], \\\\\"score\\\\\": -1.597, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 84, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.147, 0.898, 0.104, -0.366, 0.069, -0.039, 0.0, 0.0], \\\\\"score\\\\\": -1.816, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 86, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.148, 0.882, 0.074, -0.38, 0.066, -0.008, 0.0, 0.0], \\\\\"score\\\\\": -1.548, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 88, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.149, 0.866, 0.07, -0.366, 0.062, -0.063, 0.0, 0.0], \\\\\"score\\\\\": -1.734, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 90, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.151, 0.849, 0.067, -0.369, 0.061, -0.005, 0.0, 0.0], \\\\\"score\\\\\": 2.859, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 92, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.152, 0.833, 0.069, -0.33, 0.06, 0.005, 0.0, 0.0], \\\\\"score\\\\\": 3.483, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 94, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.153, 0.817, 0.065, -0.359, 0.057, -0.037, 0.0, 0.0], \\\\\"score\\\\\": 0.585, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 96, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.154, 0.8, 0.054, -0.385, 0.057, -0.0, 0.0, 0.0], \\\\\"score\\\\\": 0.799, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 98, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.155, 0.784, 0.06, -0.349, 0.058, 0.013, 0.0, 0.0], \\\\\"score\\\\\": 0.896, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 100, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.157, 0.769, 0.071, -0.346, 0.058, -0.012, 0.0, 0.0], \\\\\"score\\\\\": -2.006, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 102, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.158, 0.755, 0.052, -0.333, 0.059, 0.025, 0.0, 0.0], \\\\\"score\\\\\": -1.941, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 104, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.159, 0.739, 0.076, -0.349, 0.057, -0.009, 0.0, 0.0], \\\\\"score\\\\\": 1.305, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 106, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.161, 0.723, 0.057, -0.326, 0.056, -0.021, 0.0, 0.0], \\\\\"score\\\\\": 3.367, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 108, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.162, 0.709, 0.045, -0.311, 0.058, 0.024, 0.0, 0.0], \\\\\"score\\\\\": 4.417, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 110, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.163, 0.693, 0.047, -0.364, 0.058, 0.012, 0.0, 0.0], \\\\\"score\\\\\": -1.852, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 112, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.163, 0.677, 0.037, -0.332, 0.058, 0.009, 0.0, 0.0], \\\\\"score\\\\\": 3.865, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 114, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.164, 0.661, 0.055, -0.333, 0.055, -0.019, 0.0, 0.0], \\\\\"score\\\\\": 2.887, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 116, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.165, 0.646, 0.039, -0.346, 0.057, 0.02, 0.0, 0.0], \\\\\"score\\\\\": 1.797, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 118, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.166, 0.629, 0.038, -0.355, 0.054, -0.036, 0.0, 0.0], \\\\\"score\\\\\": 2.519, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 120, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.167, 0.613, 0.032, -0.373, 0.054, 0.02, 0.0, 0.0], \\\\\"score\\\\\": -1.863, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 122, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.168, 0.596, 0.042, -0.37, 0.057, 0.034, 0.0, 0.0], \\\\\"score\\\\\": 0.609, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 124, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.168, 0.58, 0.035, -0.385, 0.057, -0.011, 0.0, 0.0], \\\\\"score\\\\\": -1.8, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 126, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.168, 0.563, 0.0, -0.374, 0.054, -0.039, 0.0, 0.0], \\\\\"score\\\\\": 0.886, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 128, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.168, 0.546, -0.012, -0.376, 0.05, -0.047, 0.0, 0.0], \\\\\"score\\\\\": 0.671, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 130, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.168, 0.529, -0.03, -0.375, 0.047, -0.01, 0.0, 0.0], \\\\\"score\\\\\": -1.941, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 132, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.167, 0.514, -0.013, -0.365, 0.045, -0.032, 0.0, 0.0], \\\\\"score\\\\\": -1.729, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 134, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.167, 0.498, -0.031, -0.334, 0.041, -0.043, 0.0, 0.0], \\\\\"score\\\\\": 2.897, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 136, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.166, 0.481, -0.033, -0.388, 0.039, -0.033, 0.0, 0.0], \\\\\"score\\\\\": -1.58, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 138, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.165, 0.466, -0.07, -0.314, 0.034, -0.061, 0.0, 0.0], \\\\\"score\\\\\": 4.248, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 140, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.163, 0.45, -0.067, -0.366, 0.024, -0.075, 0.0, 0.0], \\\\\"score\\\\\": -1.592, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 142, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.162, 0.435, -0.076, -0.359, 0.02, -0.024, 0.0, 0.0], \\\\\"score\\\\\": -1.96, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 144, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.16, 0.419, -0.067, -0.364, 0.015, -0.062, 0.0, 0.0], \\\\\"score\\\\\": -1.297, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 146, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.159, 0.403, -0.075, -0.376, 0.012, -0.011, 0.0, 0.0], \\\\\"score\\\\\": -2.034, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 148, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.157, 0.387, -0.083, -0.35, 0.011, -0.018, 0.0, 0.0], \\\\\"score\\\\\": 1.16, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 150, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.156, 0.371, -0.079, -0.363, 0.006, -0.067, 0.0, 0.0], \\\\\"score\\\\\": -1.251, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 152, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.154, 0.356, -0.065, -0.313, 0.001, -0.053, 0.0, 0.0], \\\\\"score\\\\\": 4.48, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 154, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.153, 0.342, -0.069, -0.304, -0.0, -0.008, 0.0, 0.0], \\\\\"score\\\\\": 3.98, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 156, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.151, 0.326, -0.07, -0.357, 0.001, -0.005, 0.0, 0.0], \\\\\"score\\\\\": -1.649, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 158, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.15, 0.312, -0.068, -0.297, 0.0, -0.003, 0.0, 0.0], \\\\\"score\\\\\": 3.459, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 160, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.148, 0.297, -0.067, -0.351, 0.001, -0.009, 0.0, 0.0], \\\\\"score\\\\\": -1.663, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 162, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.147, 0.281, -0.036, -0.347, 0.003, 0.021, 0.0, 0.0], \\\\\"score\\\\\": 0.805, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 164, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.147, 0.268, -0.023, -0.28, 0.006, 0.034, 0.0, 0.0], \\\\\"score\\\\\": 3.485, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 166, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.146, 0.255, -0.049, -0.282, 0.013, 0.065, 0.0, 0.0], \\\\\"score\\\\\": 2.125, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 168, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.145, 0.241, -0.039, -0.286, 0.016, 0.034, 0.0, 0.0], \\\\\"score\\\\\": 2.398, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 170, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.145, 0.229, -0.028, -0.294, 0.017, -0.011, 0.0, 0.0], \\\\\"score\\\\\": -1.871, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 172, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.144, 0.215, -0.052, -0.281, 0.019, 0.014, 0.0, 0.0], \\\\\"score\\\\\": 3.903, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 174, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.142, 0.203, -0.072, -0.252, 0.019, -0.002, 0.0, 0.0], \\\\\"score\\\\\": 2.742, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 176, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.141, 0.191, -0.048, -0.265, 0.015, -0.032, 0.0, 0.0], \\\\\"score\\\\\": 1.835, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 178, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.14, 0.178, -0.067, -0.278, 0.016, 0.006, 0.0, 0.0], \\\\\"score\\\\\": 1.368, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 180, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.138, 0.167, -0.083, -0.234, 0.016, -0.008, 0.0, 0.0], \\\\\"score\\\\\": 3.916, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 182, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.137, 0.157, -0.062, -0.197, 0.016, 0.014, 0.0, 0.0], \\\\\"score\\\\\": 2.587, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 184, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.136, 0.149, -0.052, -0.191, 0.015, -0.036, 0.0, 0.0], \\\\\"score\\\\\": -1.639, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 186, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.135, 0.14, -0.048, -0.215, 0.015, 0.007, 0.0, 0.0], \\\\\"score\\\\\": 0.55, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 188, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.134, 0.132, -0.057, -0.165, 0.015, 0.0, 0.0, 0.0], \\\\\"score\\\\\": 2.454, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 190, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.132, 0.124, -0.076, -0.157, 0.019, 0.034, 0.0, 0.0], \\\\\"score\\\\\": 2.728, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 192, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.131, 0.116, -0.053, -0.173, 0.019, 0.01, 0.0, 0.0], \\\\\"score\\\\\": 1.411, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 194, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.13, 0.11, -0.057, -0.097, 0.019, 0.009, 0.0, 0.0], \\\\\"score\\\\\": 4.18, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 196, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.129, 0.104, -0.053, -0.151, 0.021, -0.007, 0.0, 0.0], \\\\\"score\\\\\": -1.711, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 198, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.128, 0.096, -0.049, -0.176, 0.025, 0.043, 0.0, 0.0], \\\\\"score\\\\\": 0.251, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 200, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.126, 0.088, -0.051, -0.175, 0.029, 0.044, 0.0, 0.0], \\\\\"score\\\\\": 0.331, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 202, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.126, 0.081, -0.057, -0.142, 0.034, 0.042, 0.0, 0.0], \\\\\"score\\\\\": 1.732, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 204, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.124, 0.075, -0.066, -0.12, 0.037, 0.037, 0.0, 0.0], \\\\\"score\\\\\": 2.295, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 206, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.123, 0.068, -0.062, -0.174, 0.037, 0.024, 0.0, 0.0], \\\\\"score\\\\\": -2.76, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 208, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.122, 0.061, -0.065, -0.161, 0.042, 0.066, 0.0, 0.0], \\\\\"score\\\\\": -2.92, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 210, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.12, 0.054, -0.079, -0.16, 0.048, 0.056, 0.0, 0.0], \\\\\"score\\\\\": -0.221, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 212, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.119, 0.047, -0.085, -0.15, 0.049, 0.002, 0.0, 0.0], \\\\\"score\\\\\": 2.466, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 214, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.117, 0.041, -0.089, -0.147, 0.046, -0.052, 0.0, 0.0], \\\\\"score\\\\\": -1.106, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 216, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.115, 0.035, -0.079, -0.131, 0.039, -0.09, 0.0, 0.0], \\\\\"score\\\\\": -0.975, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 218, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.113, 0.029, -0.101, -0.129, 0.033, -0.069, 0.0, 0.0], \\\\\"score\\\\\": 1.888, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 220, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.111, 0.024, -0.118, -0.086, 0.024, -0.081, 0.0, 0.0], \\\\\"score\\\\\": 2.802, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 222, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.109, 0.018, -0.119, -0.139, 0.014, -0.077, 0.0, 0.0], \\\\\"score\\\\\": -2.236, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 224, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.106, 0.013, -0.136, -0.125, 0.008, -0.048, 0.0, 0.0], \\\\\"score\\\\\": -2.017, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 226, \\\\\"action\\\\\": 1, \\\\\"current status\\\\\": [0.103, 0.008, -0.132, -0.125, 0.007, 0.007, 0.0, 0.0], \\\\\"score\\\\\": -2.437, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 228, \\\\\"action\\\\\": 3, \\\\\"current status\\\\\": [0.101, 0.003, -0.125, -0.137, 0.006, -0.027, 0.0, 0.0], \\\\\"score\\\\\": -1.037, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 230, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.098, -0.003, -0.128, -0.111, 0.002, -0.029, 0.0, 0.0], \\\\\"score\\\\\": 1.358, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 232, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.096, -0.003, -0.109, -0.006, 0.001, -0.005, 1.0, 1.0], \\\\\"score\\\\\": 1.576, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 234, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.094, -0.002, -0.088, 0.042, 0.002, 0.009, 1.0, 1.0], \\\\\"score\\\\\": 0.319, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 236, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.092, -0.001, -0.081, 0.022, -0.009, -0.075, 1.0, 1.0], \\\\\"score\\\\\": 0.72, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 238, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.091, 0.0, -0.085, 0.031, -0.007, 0.058, 1.0, 0.0], \\\\\"score\\\\\": -0.961, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 240, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.089, 0.001, -0.081, 0.02, -0.002, 0.051, 1.0, 0.0], \\\\\"score\\\\\": 0.256, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 242, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.087, 0.002, -0.08, 0.007, 0.004, 0.052, 0.0, 0.0], \\\\\"score\\\\\": 0.468, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 244, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.086, 0.0, -0.076, -0.033, 0.0, -0.115, 0.0, 1.0], \\\\\"score\\\\\": 10.622, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 246, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.084, -0.001, -0.089, -0.0, -0.009, 0.0, 1.0, 0.0], \\\\\"score\\\\\": 0.542, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 248, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.083, 0.001, -0.078, 0.03, 0.001, 0.086, 1.0, 0.0], \\\\\"score\\\\\": -0.668, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 250, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.081, 0.002, -0.09, 0.016, 0.008, 0.075, 0.0, 0.0], \\\\\"score\\\\\": 0.521, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 252, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.079, 0.001, -0.086, -0.024, 0.008, -0.087, 0.0, 1.0], \\\\\"score\\\\\": 10.638, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 254, \\\\\"action\\\\\": 2, \\\\\"current status\\\\\": [0.077, 0.0, -0.081, -0.001, -0.0, -0.002, 1.0, 1.0], \\\\\"score\\\\\": 11.223, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 256, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.076, 0.0, -0.07, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.633, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 258, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.075, 0.0, -0.058, -0.0, -0.0, 0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.624, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 260, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.074, 0.0, -0.047, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.613, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 262, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.073, 0.0, -0.036, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.601, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 264, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, -0.024, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.59, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 266, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, -0.013, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.579, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 268, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, -0.002, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.567, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 270, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, 0.001, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": -0.016, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 272, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, -0.0, -0.0, -0.0, 0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.038, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 274, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, -0.0, -0.0, -0.0, 0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.013, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 276, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, 0.0, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": -0.004, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 278, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, 0.0, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.002, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 280, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, -0.0, -0.0, -0.0, 0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.0, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 282, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, 0.0, 0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.0, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 284, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, 0.0, -0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.0, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 286, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, -0.0, -0.0, -0.0, 0.0, 1.0, 1.0], \\\\\"score\\\\\": -0.0, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 288, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, -0.0, -0.0, -0.0, 0.0, 1.0, 1.0], \\\\\"score\\\\\": 0.0, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 290, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, 0.0, -0.0, -0.0, -0.0, 1.0, 1.0], \\\\\"score\\\\\": -0.0, \\\\\"completed\\\\\": false}\", \"{\\\\\"instant\\\\\": 292, \\\\\"action\\\\\": 0, \\\\\"current status\\\\\": [0.072, 0.0, 0.0, 0.0, -0.0, 0.0, 1.0, 1.0], \\\\\"score\\\\\": 100, \\\\\"completed\\\\\": true}\"], \"total score\": 250.95603853587886}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import DuelingDQN\n",
    "\n",
    "agent = DuelingDQN.Agent(num_observaciones=8, num_acciones=4, red_modelo=DuelingDQN.DuelingQNetwork, seed=0)\n",
    "# Cargamos los pesos del agente entrenado.\n",
    "agent.load_weights('checkpoint_Dueling.pth')\n",
    "\n",
    "success_logs = lunar_lander(n_games=1, display=True, seed=42, agent=agent)\n",
    "success_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucle iterativo\n",
    "\n",
    "Sección principal del código encargada de conectar con el asistente de la API de OpenAI e iterar en la generación de código nuevo a partir de los registros del generado previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback, importlib\n",
    "import Action\n",
    "\n",
    "Action = importlib.reload(Action)\n",
    "\n",
    "def create_and_run_llm_loop(Incial_msg, logger, model=\"gpt-3.5-turbo\", num_iterations=10):\n",
    "    \n",
    "    agente = AssistantOpenAI(ARCLABKEY_OPENAI)\n",
    "\n",
    "    # Crea un asistente\n",
    "    asistente = agente.create_assistant(model=model, description=DESCRIPTION, instructions=INSTRUCTIONS, name=NAME, tools=TOOLS)\n",
    "    \n",
    "    # Crea un hilo\n",
    "    hilo = agente.create_thread()\n",
    "    \n",
    "    # Añade un mensaje inicial al hilo.\n",
    "    msg = agente.add_message(hilo.id, role=\"user\", content=Incial_msg)\n",
    "\n",
    "    # Bucle de aprendizaje del asistente.\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        logger.info(f\"Iteration: {i+1}\")\n",
    "        compiled = False\n",
    "\n",
    "        # Si en la presente iteración no se ha compilado el código, se pide al asistente corregir los errores antes de iterar.\n",
    "        while not compiled:\n",
    "            # Ejecuta el hilo\n",
    "            ejecucion = agente.run(hilo.id, asistente.id)\n",
    "            response = agente.get_run(ejecucion.id, hilo.id)\n",
    "\n",
    "            # Esperamos a que la respuesta esté lista.\n",
    "            while response.status not in [\"completed\", \"failed\", \"requires_action\"]:\n",
    "                logger.info(f\"Status: {ejecucion.status}\")\n",
    "                response = agente.get_run(ejecucion.id, hilo.id)\n",
    "                time.sleep(20)\n",
    "\n",
    "            # Descomponemos los elementos de la respuesta.\n",
    "            logger.info(f\"Status: {response.status}\")\n",
    "            if response.status == \"completed\":\n",
    "                return response\n",
    "            tool_call = response.required_action.submit_tool_outputs.tool_calls\n",
    "            print(f\"Tool call: {tool_call}\")\n",
    "\n",
    "            # Convierte el string a un diccionario\n",
    "            code_dict = json.loads(tool_call[0].function.arguments)\n",
    "            logger.info(f\"Arguments: {code_dict}\")\n",
    "            \n",
    "            # Obtén el código Python de la llamada a la herramienta\n",
    "            code = code_dict[\"code\"]\n",
    "            filename = code_dict[\"filename\"]  \n",
    "\n",
    "            logger.info(f\"\\nCodigo generado:\\n{code}\")\n",
    "\n",
    "            # Ejecuta el código Python\n",
    "            try:\n",
    "                store_code_in_file(code, filename)\n",
    "                time.sleep(1) # Pequeño retraso para que el sistema operativo pueda reflejar los cambios en el archivo\n",
    "                \n",
    "                # Hacemos commit de los cambios en el repositorio para analizar las modificaciones del agente.\n",
    "                commit_changes(r\"C:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\", f\"Second 4o execution (half logs). Iteration {i+1}.\") \n",
    "                \n",
    "                importlib.reload(Action) # Recargamos el módulo de acciones para que se actualice con las modificaciones del agente.\n",
    "\n",
    "                # Ejecutamos el código generado.\n",
    "                logs = lunar_lander(n_games=1, display=True, recoder=True, video_filename=f\"video/iteration_{i+1}.mp4\")\n",
    "                \n",
    "                # Devolvemos la respuesta al asistente.\n",
    "                for call in tool_call:\n",
    "                    agente.devolver_respuesta(response.id, hilo.id, tool_outputs=[{\"tool_call_id\": call.id, \"output\": \"Run successful.\"}])            \n",
    "                compiled = True\n",
    "                logger.info(f\"Compilación exitosa.\")\n",
    "                \n",
    "                # Esperamos a que el agente esté listo para recibir mensajes y le añadimos el resultado de la iteración.\n",
    "                while response.status not in [\"completed\", \"failed\", \"expired\"]:\n",
    "                    logger.info(f\"Status: {response.status}\")\n",
    "                    response = agente.get_run(response.id, hilo.id)\n",
    "                    time.sleep(20)\n",
    "                \n",
    "                msg = f\"\"\"These are the logs generated in the last execution{logs}. You have to improve the last code generated to maximize the reward. Please, make it more efficient, faster and more robust.\"\"\"\n",
    "                logger.info(msg)    \n",
    "                agente.add_message(hilo.id, role=\"user\", content=msg)\n",
    "            \n",
    "            # Alimentamos el asistente con el error generado en la ejecución del código.    \n",
    "            except Exception as e:\n",
    "                logger.exception(\"Error: %s\", e)\n",
    "                error_trace = traceback.format_exc()\n",
    "                for call in tool_call:\n",
    "                    agente.devolver_respuesta(response.id, hilo.id, tool_outputs=[{\"tool_call_id\": call.id, \"output\": \"ERROR.\"}]) \n",
    "                logger.error(f\"Error: {e}.\")\n",
    "                while response.status not in [\"completed\", \"failed\", \"expired\"]:\n",
    "                    logger.info(f\"Status: {response.status}\")\n",
    "                    response = agente.get_run(ejecucion.id, hilo.id)\n",
    "                    time.sleep(30)\n",
    "                msg = f\"The code generated has an error. Please, try again. Error: {e}. Trace: {error_trace}\"   \n",
    "                logger.error(msg)   \n",
    "                agente.add_message(hilo.id, role=\"assistant\", content=msg)\n",
    "    \n",
    "    agente.mostrar_mensajes(hilo.id)  \n",
    "    vaciar_agente(agente)\n",
    "    \n",
    "    logger.info(\"\\nEjecución finalizada.\\n\\n\")       \n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def vaciar_agente(agente):\n",
    "    for assistant in agente.assistants:\n",
    "        agente.delete_assistant(assistant)\n",
    "\n",
    "    for thread in agente.threads:\n",
    "        agente.delete_thread(thread)\n",
    "        \n",
    "    print(\"Asistente vaciado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configura_log(nombre_archivo):\n",
    "    \"\"\" \n",
    "    Configura el logger para que guarde los logs en un archivo y los muestre en la consola.\n",
    "    \n",
    "    Args:\n",
    "        nombre_archivo: str Nombre del archivo donde se guardarán los logs.\n",
    "        \n",
    "    Returns:\n",
    "        logger: logging.Logger Objeto logger configurado.\n",
    "    \"\"\"\n",
    "    # Crear la carpeta logs si no existe\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "    # Configura el logger\n",
    "    logging.basicConfig(filename=f'logs/{nombre_archivo}', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    # Añade un StreamHandler para mostrar los logs en la consola\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución con el asistente\n",
    "\n",
    "Prompt inicial y mensajes del sistema para el asistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:48:30,212 - INFO - HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:48:30,425 - INFO - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:48:30,685 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/messages \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:48:30,809 - INFO - Iteration: 1\n",
      "2024-06-12 13:48:31,298 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:48:31,548 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_aIbNeDYxiRSss4cF3flBiLaX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:48:31,548 - INFO - Status: queued\n",
      "2024-06-12 13:48:31,810 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_aIbNeDYxiRSss4cF3flBiLaX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:48:51,817 - INFO - Status: queued\n",
      "2024-06-12 13:48:52,088 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_aIbNeDYxiRSss4cF3flBiLaX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:49:12,129 - INFO - Status: requires_action\n",
      "2024-06-12 13:49:12,129 - INFO - Arguments: {'code': 'import random\\n\\nclass LunarLanderController:\\n    def __init__(self):\\n        self.steps_without_scoring_well = 0\\n\\n    def act(self, observation):\\n        \\'\\'\\'\\n        The function that codifies the action to be taken in each instant of time.\\n\\n        Args:\\n            observation (numpy.array):\\n                \"description\": \"The state of the environment after the action is taken.\",\\n                \"positions\": {  \\n                    \"0\": \"X position\",\\n                    \"1\": \"Y position\",\\n                    \"2\": \"X velocity\",\\n                    \"3\": \"Y velocity\",\\n                    \"4\": \"Angle\",\\n                    \"5\": \"Angular velocity\",\\n                    \"6\": \"Left contact sensor\",\\n                    \"7\": \"Right contact sensor\"\\n                },\\n                \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\\n                \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\\n\\n        Returns:\\n            Integer  : The action to be taken.\\n        \\'\\'\\'\\n        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\\n\\n        # If the lunar lander has landed correctly, do nothing (action 0)\\n        if left_contact == 1 and right_contact == 1:\\n            return 0\\n\\n        # If the angle is too large, attempt to correct it\\n        if angle < -0.1:\\n            return 1  # fire right engine\\n        elif angle > 0.1:\\n            return 3  # fire left engine\\n\\n        # If the lander is moving too fast horizontally, attempt to correct it\\n        if x_vel < -0.1:\\n            return 1  # fire right engine\\n        elif x_vel > 0.1:\\n            return 3  # fire left engine\\n\\n        # If the lander is falling too fast, fire the main engine\\n        if y_vel < -0.3:\\n            return 2\\n\\n        # If the lander is not descending, start descending\\n        if y_vel >= 0:\\n            return 2  # fire main engine\\n\\n        # Edge case: if point threshold without well score do random step\\n        if self.steps_without_scoring_well >= 10:\\n            self.steps_without_scoring_well = 0\\n            return random.randint(0, 3)\\n\\n        self.steps_without_scoring_well += 1\\n        return 0\\n\\n# Initialize the controller instance\\nlander_controller = LunarLanderController()', 'filename': 'Action.py'}\n",
      "2024-06-12 13:49:12,129 - INFO - \n",
      "Codigo generado:\n",
      "import random\n",
      "\n",
      "class LunarLanderController:\n",
      "    def __init__(self):\n",
      "        self.steps_without_scoring_well = 0\n",
      "\n",
      "    def act(self, observation):\n",
      "        '''\n",
      "        The function that codifies the action to be taken in each instant of time.\n",
      "\n",
      "        Args:\n",
      "            observation (numpy.array):\n",
      "                \"description\": \"The state of the environment after the action is taken.\",\n",
      "                \"positions\": {  \n",
      "                    \"0\": \"X position\",\n",
      "                    \"1\": \"Y position\",\n",
      "                    \"2\": \"X velocity\",\n",
      "                    \"3\": \"Y velocity\",\n",
      "                    \"4\": \"Angle\",\n",
      "                    \"5\": \"Angular velocity\",\n",
      "                    \"6\": \"Left contact sensor\",\n",
      "                    \"7\": \"Right contact sensor\"\n",
      "                },\n",
      "                \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\n",
      "                \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\n",
      "\n",
      "        Returns:\n",
      "            Integer  : The action to be taken.\n",
      "        '''\n",
      "        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\n",
      "\n",
      "        # If the lunar lander has landed correctly, do nothing (action 0)\n",
      "        if left_contact == 1 and right_contact == 1:\n",
      "            return 0\n",
      "\n",
      "        # If the angle is too large, attempt to correct it\n",
      "        if angle < -0.1:\n",
      "            return 1  # fire right engine\n",
      "        elif angle > 0.1:\n",
      "            return 3  # fire left engine\n",
      "\n",
      "        # If the lander is moving too fast horizontally, attempt to correct it\n",
      "        if x_vel < -0.1:\n",
      "            return 1  # fire right engine\n",
      "        elif x_vel > 0.1:\n",
      "            return 3  # fire left engine\n",
      "\n",
      "        # If the lander is falling too fast, fire the main engine\n",
      "        if y_vel < -0.3:\n",
      "            return 2\n",
      "\n",
      "        # If the lander is not descending, start descending\n",
      "        if y_vel >= 0:\n",
      "            return 2  # fire main engine\n",
      "\n",
      "        # Edge case: if point threshold without well score do random step\n",
      "        if self.steps_without_scoring_well >= 10:\n",
      "            self.steps_without_scoring_well = 0\n",
      "            return random.randint(0, 3)\n",
      "\n",
      "        self.steps_without_scoring_well += 1\n",
      "        return 0\n",
      "\n",
      "# Initialize the controller instance\n",
      "lander_controller = LunarLanderController()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call: [RequiredActionFunctionToolCall(id='call_Pykn0a8aSUK97L747DpAFDM2', function=Function(arguments='{\"code\":\"import random\\\\n\\\\nclass LunarLanderController:\\\\n    def __init__(self):\\\\n        self.steps_without_scoring_well = 0\\\\n\\\\n    def act(self, observation):\\\\n        \\'\\'\\'\\\\n        The function that codifies the action to be taken in each instant of time.\\\\n\\\\n        Args:\\\\n            observation (numpy.array):\\\\n                \\\\\"description\\\\\": \\\\\"The state of the environment after the action is taken.\\\\\",\\\\n                \\\\\"positions\\\\\": {  \\\\n                    \\\\\"0\\\\\": \\\\\"X position\\\\\",\\\\n                    \\\\\"1\\\\\": \\\\\"Y position\\\\\",\\\\n                    \\\\\"2\\\\\": \\\\\"X velocity\\\\\",\\\\n                    \\\\\"3\\\\\": \\\\\"Y velocity\\\\\",\\\\n                    \\\\\"4\\\\\": \\\\\"Angle\\\\\",\\\\n                    \\\\\"5\\\\\": \\\\\"Angular velocity\\\\\",\\\\n                    \\\\\"6\\\\\": \\\\\"Left contact sensor\\\\\",\\\\n                    \\\\\"7\\\\\": \\\\\"Right contact sensor\\\\\"\\\\n                },\\\\n                \\\\\"min_values\\\\\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\\\\n                \\\\\"max_values\\\\\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\\\\n\\\\n        Returns:\\\\n            Integer  : The action to be taken.\\\\n        \\'\\'\\'\\\\n        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\\\\n\\\\n        # If the lunar lander has landed correctly, do nothing (action 0)\\\\n        if left_contact == 1 and right_contact == 1:\\\\n            return 0\\\\n\\\\n        # If the angle is too large, attempt to correct it\\\\n        if angle < -0.1:\\\\n            return 1  # fire right engine\\\\n        elif angle > 0.1:\\\\n            return 3  # fire left engine\\\\n\\\\n        # If the lander is moving too fast horizontally, attempt to correct it\\\\n        if x_vel < -0.1:\\\\n            return 1  # fire right engine\\\\n        elif x_vel > 0.1:\\\\n            return 3  # fire left engine\\\\n\\\\n        # If the lander is falling too fast, fire the main engine\\\\n        if y_vel < -0.3:\\\\n            return 2\\\\n\\\\n        # If the lander is not descending, start descending\\\\n        if y_vel >= 0:\\\\n            return 2  # fire main engine\\\\n\\\\n        # Edge case: if point threshold without well score do random step\\\\n        if self.steps_without_scoring_well >= 10:\\\\n            self.steps_without_scoring_well = 0\\\\n            return random.randint(0, 3)\\\\n\\\\n        self.steps_without_scoring_well += 1\\\\n        return 0\\\\n\\\\n# Initialize the controller instance\\\\nlander_controller = LunarLanderController()\",\"filename\":\"Action.py\"}', name='store_code_in_file'), type='function')]\n",
      "Moviepy - Building video c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_1.mp4\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_1.mp4\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_1.mp4\\rl-video-episode-0.mp4\n",
      "Número de instantes: 97. Tamaño de logs: 49\n",
      "episode  1 score -57.134 avg score -0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:49:16,703 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_aIbNeDYxiRSss4cF3flBiLaX/submit_tool_outputs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:49:16,706 - INFO - Compilación exitosa.\n",
      "2024-06-12 13:49:16,709 - INFO - Status: requires_action\n",
      "2024-06-12 13:49:16,971 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_aIbNeDYxiRSss4cF3flBiLaX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:49:36,976 - INFO - Status: in_progress\n",
      "2024-06-12 13:49:37,557 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_aIbNeDYxiRSss4cF3flBiLaX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:49:57,563 - INFO - These are the logs generated in the last execution{\"landing attempt\": 1, \"logs\": [\"{\\\"instant\\\": 0, \\\"action\\\": 3, \\\"current status\\\": [0.008, 1.417, 0.39, 0.131, -0.01, -0.123, 0.0, 0.0], \\\"score\\\": -0.871, \\\"completed\\\": false}\", \"{\\\"instant\\\": 2, \\\"action\\\": 3, \\\"current status\\\": [0.016, 1.421, 0.412, 0.077, -0.03, -0.211, 0.0, 0.0], \\\"score\\\": -1.707, \\\"completed\\\": false}\", \"{\\\"instant\\\": 4, \\\"action\\\": 3, \\\"current status\\\": [0.024, 1.423, 0.431, 0.023, -0.056, -0.286, 0.0, 0.0], \\\"score\\\": -2.308, \\\"completed\\\": false}\", \"{\\\"instant\\\": 6, \\\"action\\\": 3, \\\"current status\\\": [0.032, 1.422, 0.45, -0.032, -0.091, -0.364, 0.0, 0.0], \\\"score\\\": -2.782, \\\"completed\\\": false}\", \"{\\\"instant\\\": 8, \\\"action\\\": 1, \\\"current status\\\": [0.041, 1.419, 0.448, -0.085, -0.128, -0.356, 0.0, 0.0], \\\"score\\\": -0.974, \\\"completed\\\": false}\", \"{\\\"instant\\\": 10, \\\"action\\\": 1, \\\"current status\\\": [0.049, 1.414, 0.43, -0.137, -0.158, -0.283, 0.0, 0.0], \\\"score\\\": -1.074, \\\"completed\\\": false}\", \"{\\\"instant\\\": 12, \\\"action\\\": 1, \\\"current status\\\": [0.058, 1.406, 0.413, -0.188, -0.182, -0.21, 0.0, 0.0], \\\"score\\\": -0.698, \\\"completed\\\": false}\", \"{\\\"instant\\\": 14, \\\"action\\\": 1, \\\"current status\\\": [0.065, 1.396, 0.394, -0.239, -0.197, -0.135, 0.0, 0.0], \\\"score\\\": -0.544, \\\"completed\\\": false}\", \"{\\\"instant\\\": 16, \\\"action\\\": 1, \\\"current status\\\": [0.073, 1.383, 0.374, -0.291, -0.205, -0.053, 0.0, 0.0], \\\"score\\\": -0.26, \\\"completed\\\": false}\", \"{\\\"instant\\\": 18, \\\"action\\\": 1, \\\"current status\\\": [0.08, 1.368, 0.352, -0.342, -0.203, 0.038, 0.0, 0.0], \\\"score\\\": 0.007, \\\"completed\\\": false}\", \"{\\\"instant\\\": 20, \\\"action\\\": 1, \\\"current status\\\": [0.087, 1.351, 0.331, -0.392, -0.193, 0.125, 0.0, 0.0], \\\"score\\\": 0.353, \\\"completed\\\": false}\", \"{\\\"instant\\\": 22, \\\"action\\\": 1, \\\"current status\\\": [0.093, 1.332, 0.312, -0.443, -0.174, 0.205, 0.0, 0.0], \\\"score\\\": 0.36, \\\"completed\\\": false}\", \"{\\\"instant\\\": 24, \\\"action\\\": 1, \\\"current status\\\": [0.1, 1.31, 0.293, -0.495, -0.148, 0.278, 0.0, 0.0], \\\"score\\\": 0.627, \\\"completed\\\": false}\", \"{\\\"instant\\\": 26, \\\"action\\\": 1, \\\"current status\\\": [0.106, 1.286, 0.273, -0.547, -0.114, 0.358, 0.0, 0.0], \\\"score\\\": 1.144, \\\"completed\\\": false}\", \"{\\\"instant\\\": 28, \\\"action\\\": 2, \\\"current status\\\": [0.111, 1.26, 0.26, -0.57, -0.074, 0.397, 0.0, 0.0], \\\"score\\\": 3.318, \\\"completed\\\": false}\", \"{\\\"instant\\\": 30, \\\"action\\\": 2, \\\"current status\\\": [0.117, 1.236, 0.269, -0.538, -0.035, 0.398, 0.0, 0.0], \\\"score\\\": 3.982, \\\"completed\\\": false}\", \"{\\\"instant\\\": 32, \\\"action\\\": 2, \\\"current status\\\": [0.122, 1.212, 0.258, -0.514, 0.004, 0.384, 0.0, 0.0], \\\"score\\\": 3.709, \\\"completed\\\": false}\", \"{\\\"instant\\\": 34, \\\"action\\\": 2, \\\"current status\\\": [0.128, 1.189, 0.253, -0.51, 0.041, 0.38, 0.0, 0.0], \\\"score\\\": -1.385, \\\"completed\\\": false}\", \"{\\\"instant\\\": 36, \\\"action\\\": 2, \\\"current status\\\": [0.133, 1.167, 0.254, -0.475, 0.08, 0.389, 0.0, 0.0], \\\"score\\\": 2.321, \\\"completed\\\": false}\", \"{\\\"instant\\\": 38, \\\"action\\\": 3, \\\"current status\\\": [0.139, 1.145, 0.27, -0.501, 0.118, 0.358, 0.0, 0.0], \\\"score\\\": -3.501, \\\"completed\\\": false}\", \"{\\\"instant\\\": 40, \\\"action\\\": 3, \\\"current status\\\": [0.145, 1.121, 0.288, -0.553, 0.149, 0.282, 0.0, 0.0], \\\"score\\\": -3.057, \\\"completed\\\": false}\", \"{\\\"instant\\\": 42, \\\"action\\\": 3, \\\"current status\\\": [0.151, 1.094, 0.309, -0.604, 0.17, 0.196, 0.0, 0.0], \\\"score\\\": -2.438, \\\"completed\\\": false}\", \"{\\\"instant\\\": 44, \\\"action\\\": 3, \\\"current status\\\": [0.158, 1.065, 0.333, -0.655, 0.182, 0.1, 0.0, 0.0], \\\"score\\\": -1.843, \\\"completed\\\": false}\", \"{\\\"instant\\\": 46, \\\"action\\\": 3, \\\"current status\\\": [0.165, 1.034, 0.35, -0.706, 0.187, 0.027, 0.0, 0.0], \\\"score\\\": -1.343, \\\"completed\\\": false}\", \"{\\\"instant\\\": 48, \\\"action\\\": 3, \\\"current status\\\": [0.172, 1.001, 0.372, -0.756, 0.183, -0.064, 0.0, 0.0], \\\"score\\\": -0.789, \\\"completed\\\": false}\", \"{\\\"instant\\\": 50, \\\"action\\\": 3, \\\"current status\\\": [0.18, 0.965, 0.391, -0.807, 0.17, -0.141, 0.0, 0.0], \\\"score\\\": -0.222, \\\"completed\\\": false}\", \"{\\\"instant\\\": 52, \\\"action\\\": 3, \\\"current status\\\": [0.188, 0.927, 0.408, -0.859, 0.151, -0.209, 0.0, 0.0], \\\"score\\\": 0.085, \\\"completed\\\": false}\", \"{\\\"instant\\\": 54, \\\"action\\\": 3, \\\"current status\\\": [0.196, 0.886, 0.428, -0.909, 0.124, -0.293, 0.0, 0.0], \\\"score\\\": 0.6, \\\"completed\\\": false}\", \"{\\\"instant\\\": 56, \\\"action\\\": 3, \\\"current status\\\": [0.204, 0.844, 0.448, -0.961, 0.089, -0.373, 0.0, 0.0], \\\"score\\\": 1.15, \\\"completed\\\": false}\", \"{\\\"instant\\\": 58, \\\"action\\\": 2, \\\"current status\\\": [0.212, 0.802, 0.411, -0.92, 0.049, -0.398, 0.0, 0.0], \\\"score\\\": 4.814, \\\"completed\\\": false}\", \"{\\\"instant\\\": 60, \\\"action\\\": 2, \\\"current status\\\": [0.22, 0.762, 0.404, -0.896, 0.01, -0.4, 0.0, 0.0], \\\"score\\\": 3.758, \\\"completed\\\": false}\", \"{\\\"instant\\\": 62, \\\"action\\\": 2, \\\"current status\\\": [0.228, 0.723, 0.406, -0.851, -0.031, -0.397, 0.0, 0.0], \\\"score\\\": 1.185, \\\"completed\\\": false}\", \"{\\\"instant\\\": 64, \\\"action\\\": 2, \\\"current status\\\": [0.236, 0.685, 0.425, -0.838, -0.069, -0.383, 0.0, 0.0], \\\"score\\\": -0.001, \\\"completed\\\": false}\", \"{\\\"instant\\\": 66, \\\"action\\\": 2, \\\"current status\\\": [0.244, 0.65, 0.443, -0.773, -0.107, -0.379, 0.0, 0.0], \\\"score\\\": 1.484, \\\"completed\\\": false}\", \"{\\\"instant\\\": 68, \\\"action\\\": 1, \\\"current status\\\": [0.252, 0.613, 0.424, -0.826, -0.14, -0.301, 0.0, 0.0], \\\"score\\\": -1.738, \\\"completed\\\": false}\", \"{\\\"instant\\\": 70, \\\"action\\\": 1, \\\"current status\\\": [0.26, 0.574, 0.404, -0.878, -0.164, -0.223, 0.0, 0.0], \\\"score\\\": -1.559, \\\"completed\\\": false}\", \"{\\\"instant\\\": 72, \\\"action\\\": 1, \\\"current status\\\": [0.268, 0.533, 0.385, -0.929, -0.18, -0.143, 0.0, 0.0], \\\"score\\\": -0.924, \\\"completed\\\": false}\", \"{\\\"instant\\\": 74, \\\"action\\\": 1, \\\"current status\\\": [0.275, 0.489, 0.365, -0.981, -0.189, -0.064, 0.0, 0.0], \\\"score\\\": -0.536, \\\"completed\\\": false}\", \"{\\\"instant\\\": 76, \\\"action\\\": 1, \\\"current status\\\": [0.282, 0.444, 0.343, -1.031, -0.189, 0.027, 0.0, 0.0], \\\"score\\\": -0.157, \\\"completed\\\": false}\", \"{\\\"instant\\\": 78, \\\"action\\\": 1, \\\"current status\\\": [0.289, 0.395, 0.324, -1.082, -0.18, 0.107, 0.0, 0.0], \\\"score\\\": 0.145, \\\"completed\\\": false}\", \"{\\\"instant\\\": 80, \\\"action\\\": 1, \\\"current status\\\": [0.295, 0.345, 0.307, -1.133, -0.164, 0.175, 0.0, 0.0], \\\"score\\\": 0.363, \\\"completed\\\": false}\", \"{\\\"instant\\\": 82, \\\"action\\\": 1, \\\"current status\\\": [0.301, 0.292, 0.289, -1.186, -0.142, 0.247, 0.0, 0.0], \\\"score\\\": 0.642, \\\"completed\\\": false}\", \"{\\\"instant\\\": 84, \\\"action\\\": 1, \\\"current status\\\": [0.307, 0.237, 0.272, -1.237, -0.112, 0.316, 0.0, 0.0], \\\"score\\\": 0.809, \\\"completed\\\": false}\", \"{\\\"instant\\\": 86, \\\"action\\\": 2, \\\"current status\\\": [0.313, 0.18, 0.276, -1.265, -0.076, 0.359, 0.0, 0.0], \\\"score\\\": 2.315, \\\"completed\\\": false}\", \"{\\\"instant\\\": 88, \\\"action\\\": 2, \\\"current status\\\": [0.319, 0.124, 0.278, -1.216, -0.041, 0.352, 0.0, 0.0], \\\"score\\\": 6.353, \\\"completed\\\": false}\", \"{\\\"instant\\\": 90, \\\"action\\\": 2, \\\"current status\\\": [0.325, 0.072, 0.279, -1.165, -0.006, 0.348, 0.0, 0.0], \\\"score\\\": 3.759, \\\"completed\\\": false}\", \"{\\\"instant\\\": 92, \\\"action\\\": 2, \\\"current status\\\": [0.331, 0.02, 0.266, -1.131, 0.029, 0.335, 0.0, 0.0], \\\"score\\\": -0.539, \\\"completed\\\": false}\", \"{\\\"instant\\\": 94, \\\"action\\\": 2, \\\"current status\\\": [0.336, -0.029, 0.273, -1.081, 0.043, -0.044, 1.0, 1.0], \\\"score\\\": 14.213, \\\"completed\\\": false}\", \"{\\\"instant\\\": 95, \\\"action\\\": 2, \\\"current status\\\": [0.338, -0.05, 0.354, -0.612, 0.009, -3.432, 1.0, 1.0], \\\"score\\\": -100, \\\"completed\\\": true}\"], \"total score\": -57.13390452568175}. You have to improve the last code generated to maximize the reward. Please, make it more efficient, faster and more robust.\n",
      "2024-06-12 13:49:57,931 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/messages \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:49:57,934 - INFO - Iteration: 2\n",
      "2024-06-12 13:49:58,443 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:49:58,750 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_UAeTn0Mf42vM2tty5BoOgZkX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:49:58,753 - INFO - Status: queued\n",
      "2024-06-12 13:49:59,058 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_UAeTn0Mf42vM2tty5BoOgZkX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:50:19,063 - INFO - Status: queued\n",
      "2024-06-12 13:50:19,434 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_UAeTn0Mf42vM2tty5BoOgZkX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:50:39,439 - INFO - Status: requires_action\n",
      "2024-06-12 13:50:39,441 - INFO - Arguments: {'code': 'import random\\n\\nclass LunarLanderController:\\n    def __init__(self):\\n        self.steps_without_scoring_well = 0\\n\\n    def act(self, observation):\\n        \\'\\'\\'\\n        The function that codifies the action to be taken in each instant of time.\\n\\n        Args:\\n            observation (numpy.array):\\n                \"description\": \"The state of the environment after the action is taken.\",\\n                \"positions\": {  \\n                    \"0\": \"X position\",\\n                    \"1\": \"Y position\",\\n                    \"2\": \"X velocity\",\\n                    \"3\": \"Y velocity\",\\n                    \"4\": \"Angle\",\\n                    \"5\": \"Angular velocity\",\\n                    \"6\": \"Left contact sensor\",\\n                    \"7\": \"Right contact sensor\"\\n                },\\n                \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\\n                \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\\n\\n        Returns:\\n            Integer  : The action to be taken.\\n        \\'\\'\\'\\n        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\\n\\n        # If the lunar lander has landed correctly, do nothing (action 0)\\n        if left_contact == 1 and right_contact == 1:\\n            return 0\\n\\n        # If the angle is too large, attempt to correct it\\n        if angle < -0.05:\\n            return 1  # fire right engine\\n        elif angle > 0.05:\\n            return 3  # fire left engine\\n\\n        # If the lander is moving too fast horizontally, attempt to correct it\\n        if x_vel < -0.1:\\n            return 1  # fire right engine\\n        elif x_vel > 0.1:\\n            return 3  # fire left engine\\n\\n        # If the lander is falling too fast, fire the main engine\\n        if y_vel < -0.2:\\n            return 2\\n\\n        # If the lander is not descending, start descending\\n        if y_vel >= 0:\\n            return 2  # fire main engine\\n\\n        # Edge case: if point threshold without well score perform random step\\n        if self.steps_without_scoring_well >= 5:\\n            self.steps_without_scoring_well = 0\\n            return random.randint(0, 3)\\n\\n        self.steps_without_scoring_well += 1\\n        return 0\\n\\n# Initialize the controller instance\\nlander_controller = LunarLanderController()', 'filename': 'Action.py'}\n",
      "2024-06-12 13:50:39,443 - INFO - \n",
      "Codigo generado:\n",
      "import random\n",
      "\n",
      "class LunarLanderController:\n",
      "    def __init__(self):\n",
      "        self.steps_without_scoring_well = 0\n",
      "\n",
      "    def act(self, observation):\n",
      "        '''\n",
      "        The function that codifies the action to be taken in each instant of time.\n",
      "\n",
      "        Args:\n",
      "            observation (numpy.array):\n",
      "                \"description\": \"The state of the environment after the action is taken.\",\n",
      "                \"positions\": {  \n",
      "                    \"0\": \"X position\",\n",
      "                    \"1\": \"Y position\",\n",
      "                    \"2\": \"X velocity\",\n",
      "                    \"3\": \"Y velocity\",\n",
      "                    \"4\": \"Angle\",\n",
      "                    \"5\": \"Angular velocity\",\n",
      "                    \"6\": \"Left contact sensor\",\n",
      "                    \"7\": \"Right contact sensor\"\n",
      "                },\n",
      "                \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\n",
      "                \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\n",
      "\n",
      "        Returns:\n",
      "            Integer  : The action to be taken.\n",
      "        '''\n",
      "        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\n",
      "\n",
      "        # If the lunar lander has landed correctly, do nothing (action 0)\n",
      "        if left_contact == 1 and right_contact == 1:\n",
      "            return 0\n",
      "\n",
      "        # If the angle is too large, attempt to correct it\n",
      "        if angle < -0.05:\n",
      "            return 1  # fire right engine\n",
      "        elif angle > 0.05:\n",
      "            return 3  # fire left engine\n",
      "\n",
      "        # If the lander is moving too fast horizontally, attempt to correct it\n",
      "        if x_vel < -0.1:\n",
      "            return 1  # fire right engine\n",
      "        elif x_vel > 0.1:\n",
      "            return 3  # fire left engine\n",
      "\n",
      "        # If the lander is falling too fast, fire the main engine\n",
      "        if y_vel < -0.2:\n",
      "            return 2\n",
      "\n",
      "        # If the lander is not descending, start descending\n",
      "        if y_vel >= 0:\n",
      "            return 2  # fire main engine\n",
      "\n",
      "        # Edge case: if point threshold without well score perform random step\n",
      "        if self.steps_without_scoring_well >= 5:\n",
      "            self.steps_without_scoring_well = 0\n",
      "            return random.randint(0, 3)\n",
      "\n",
      "        self.steps_without_scoring_well += 1\n",
      "        return 0\n",
      "\n",
      "# Initialize the controller instance\n",
      "lander_controller = LunarLanderController()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call: [RequiredActionFunctionToolCall(id='call_v0o87Cw4xtExiqFcfHzxEP9G', function=Function(arguments='{\"code\":\"import random\\\\n\\\\nclass LunarLanderController:\\\\n    def __init__(self):\\\\n        self.steps_without_scoring_well = 0\\\\n\\\\n    def act(self, observation):\\\\n        \\'\\'\\'\\\\n        The function that codifies the action to be taken in each instant of time.\\\\n\\\\n        Args:\\\\n            observation (numpy.array):\\\\n                \\\\\"description\\\\\": \\\\\"The state of the environment after the action is taken.\\\\\",\\\\n                \\\\\"positions\\\\\": {  \\\\n                    \\\\\"0\\\\\": \\\\\"X position\\\\\",\\\\n                    \\\\\"1\\\\\": \\\\\"Y position\\\\\",\\\\n                    \\\\\"2\\\\\": \\\\\"X velocity\\\\\",\\\\n                    \\\\\"3\\\\\": \\\\\"Y velocity\\\\\",\\\\n                    \\\\\"4\\\\\": \\\\\"Angle\\\\\",\\\\n                    \\\\\"5\\\\\": \\\\\"Angular velocity\\\\\",\\\\n                    \\\\\"6\\\\\": \\\\\"Left contact sensor\\\\\",\\\\n                    \\\\\"7\\\\\": \\\\\"Right contact sensor\\\\\"\\\\n                },\\\\n                \\\\\"min_values\\\\\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\\\\n                \\\\\"max_values\\\\\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\\\\n\\\\n        Returns:\\\\n            Integer  : The action to be taken.\\\\n        \\'\\'\\'\\\\n        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\\\\n\\\\n        # If the lunar lander has landed correctly, do nothing (action 0)\\\\n        if left_contact == 1 and right_contact == 1:\\\\n            return 0\\\\n\\\\n        # If the angle is too large, attempt to correct it\\\\n        if angle < -0.05:\\\\n            return 1  # fire right engine\\\\n        elif angle > 0.05:\\\\n            return 3  # fire left engine\\\\n\\\\n        # If the lander is moving too fast horizontally, attempt to correct it\\\\n        if x_vel < -0.1:\\\\n            return 1  # fire right engine\\\\n        elif x_vel > 0.1:\\\\n            return 3  # fire left engine\\\\n\\\\n        # If the lander is falling too fast, fire the main engine\\\\n        if y_vel < -0.2:\\\\n            return 2\\\\n\\\\n        # If the lander is not descending, start descending\\\\n        if y_vel >= 0:\\\\n            return 2  # fire main engine\\\\n\\\\n        # Edge case: if point threshold without well score perform random step\\\\n        if self.steps_without_scoring_well >= 5:\\\\n            self.steps_without_scoring_well = 0\\\\n            return random.randint(0, 3)\\\\n\\\\n        self.steps_without_scoring_well += 1\\\\n        return 0\\\\n\\\\n# Initialize the controller instance\\\\nlander_controller = LunarLanderController()\",\"filename\":\"Action.py\"}', name='store_code_in_file'), type='function')]\n",
      "Moviepy - Building video c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_2.mp4\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_2.mp4\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_2.mp4\\rl-video-episode-0.mp4\n",
      "Número de instantes: 97. Tamaño de logs: 49\n",
      "episode  1 score -57.134 avg score -0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:50:43,909 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_UAeTn0Mf42vM2tty5BoOgZkX/submit_tool_outputs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:50:43,912 - INFO - Compilación exitosa.\n",
      "2024-06-12 13:50:43,914 - INFO - Status: requires_action\n",
      "2024-06-12 13:50:44,215 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_UAeTn0Mf42vM2tty5BoOgZkX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:51:04,219 - INFO - Status: in_progress\n",
      "2024-06-12 13:51:04,595 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_UAeTn0Mf42vM2tty5BoOgZkX \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:51:24,599 - INFO - These are the logs generated in the last execution{\"landing attempt\": 1, \"logs\": [\"{\\\"instant\\\": 0, \\\"action\\\": 3, \\\"current status\\\": [0.008, 1.417, 0.39, 0.131, -0.01, -0.123, 0.0, 0.0], \\\"score\\\": -0.871, \\\"completed\\\": false}\", \"{\\\"instant\\\": 2, \\\"action\\\": 3, \\\"current status\\\": [0.016, 1.421, 0.412, 0.077, -0.03, -0.211, 0.0, 0.0], \\\"score\\\": -1.707, \\\"completed\\\": false}\", \"{\\\"instant\\\": 4, \\\"action\\\": 3, \\\"current status\\\": [0.024, 1.423, 0.431, 0.023, -0.056, -0.286, 0.0, 0.0], \\\"score\\\": -2.308, \\\"completed\\\": false}\", \"{\\\"instant\\\": 6, \\\"action\\\": 3, \\\"current status\\\": [0.032, 1.422, 0.45, -0.032, -0.091, -0.364, 0.0, 0.0], \\\"score\\\": -2.782, \\\"completed\\\": false}\", \"{\\\"instant\\\": 8, \\\"action\\\": 1, \\\"current status\\\": [0.041, 1.419, 0.448, -0.085, -0.128, -0.356, 0.0, 0.0], \\\"score\\\": -0.974, \\\"completed\\\": false}\", \"{\\\"instant\\\": 10, \\\"action\\\": 1, \\\"current status\\\": [0.049, 1.414, 0.43, -0.137, -0.158, -0.283, 0.0, 0.0], \\\"score\\\": -1.074, \\\"completed\\\": false}\", \"{\\\"instant\\\": 12, \\\"action\\\": 1, \\\"current status\\\": [0.058, 1.406, 0.413, -0.188, -0.182, -0.21, 0.0, 0.0], \\\"score\\\": -0.698, \\\"completed\\\": false}\", \"{\\\"instant\\\": 14, \\\"action\\\": 1, \\\"current status\\\": [0.065, 1.396, 0.394, -0.239, -0.197, -0.135, 0.0, 0.0], \\\"score\\\": -0.544, \\\"completed\\\": false}\", \"{\\\"instant\\\": 16, \\\"action\\\": 1, \\\"current status\\\": [0.073, 1.383, 0.374, -0.291, -0.205, -0.053, 0.0, 0.0], \\\"score\\\": -0.26, \\\"completed\\\": false}\", \"{\\\"instant\\\": 18, \\\"action\\\": 1, \\\"current status\\\": [0.08, 1.368, 0.352, -0.342, -0.203, 0.038, 0.0, 0.0], \\\"score\\\": 0.007, \\\"completed\\\": false}\", \"{\\\"instant\\\": 20, \\\"action\\\": 1, \\\"current status\\\": [0.087, 1.351, 0.331, -0.392, -0.193, 0.125, 0.0, 0.0], \\\"score\\\": 0.353, \\\"completed\\\": false}\", \"{\\\"instant\\\": 22, \\\"action\\\": 1, \\\"current status\\\": [0.093, 1.332, 0.312, -0.443, -0.174, 0.205, 0.0, 0.0], \\\"score\\\": 0.36, \\\"completed\\\": false}\", \"{\\\"instant\\\": 24, \\\"action\\\": 1, \\\"current status\\\": [0.1, 1.31, 0.293, -0.495, -0.148, 0.278, 0.0, 0.0], \\\"score\\\": 0.627, \\\"completed\\\": false}\", \"{\\\"instant\\\": 26, \\\"action\\\": 1, \\\"current status\\\": [0.106, 1.286, 0.273, -0.547, -0.114, 0.358, 0.0, 0.0], \\\"score\\\": 1.144, \\\"completed\\\": false}\", \"{\\\"instant\\\": 28, \\\"action\\\": 2, \\\"current status\\\": [0.111, 1.26, 0.26, -0.57, -0.074, 0.397, 0.0, 0.0], \\\"score\\\": 3.318, \\\"completed\\\": false}\", \"{\\\"instant\\\": 30, \\\"action\\\": 2, \\\"current status\\\": [0.117, 1.236, 0.269, -0.538, -0.035, 0.398, 0.0, 0.0], \\\"score\\\": 3.982, \\\"completed\\\": false}\", \"{\\\"instant\\\": 32, \\\"action\\\": 2, \\\"current status\\\": [0.122, 1.212, 0.258, -0.514, 0.004, 0.384, 0.0, 0.0], \\\"score\\\": 3.709, \\\"completed\\\": false}\", \"{\\\"instant\\\": 34, \\\"action\\\": 2, \\\"current status\\\": [0.128, 1.189, 0.253, -0.51, 0.041, 0.38, 0.0, 0.0], \\\"score\\\": -1.385, \\\"completed\\\": false}\", \"{\\\"instant\\\": 36, \\\"action\\\": 2, \\\"current status\\\": [0.133, 1.167, 0.254, -0.475, 0.08, 0.389, 0.0, 0.0], \\\"score\\\": 2.321, \\\"completed\\\": false}\", \"{\\\"instant\\\": 38, \\\"action\\\": 3, \\\"current status\\\": [0.139, 1.145, 0.27, -0.501, 0.118, 0.358, 0.0, 0.0], \\\"score\\\": -3.501, \\\"completed\\\": false}\", \"{\\\"instant\\\": 40, \\\"action\\\": 3, \\\"current status\\\": [0.145, 1.121, 0.288, -0.553, 0.149, 0.282, 0.0, 0.0], \\\"score\\\": -3.057, \\\"completed\\\": false}\", \"{\\\"instant\\\": 42, \\\"action\\\": 3, \\\"current status\\\": [0.151, 1.094, 0.309, -0.604, 0.17, 0.196, 0.0, 0.0], \\\"score\\\": -2.438, \\\"completed\\\": false}\", \"{\\\"instant\\\": 44, \\\"action\\\": 3, \\\"current status\\\": [0.158, 1.065, 0.333, -0.655, 0.182, 0.1, 0.0, 0.0], \\\"score\\\": -1.843, \\\"completed\\\": false}\", \"{\\\"instant\\\": 46, \\\"action\\\": 3, \\\"current status\\\": [0.165, 1.034, 0.35, -0.706, 0.187, 0.027, 0.0, 0.0], \\\"score\\\": -1.343, \\\"completed\\\": false}\", \"{\\\"instant\\\": 48, \\\"action\\\": 3, \\\"current status\\\": [0.172, 1.001, 0.372, -0.756, 0.183, -0.064, 0.0, 0.0], \\\"score\\\": -0.789, \\\"completed\\\": false}\", \"{\\\"instant\\\": 50, \\\"action\\\": 3, \\\"current status\\\": [0.18, 0.965, 0.391, -0.807, 0.17, -0.141, 0.0, 0.0], \\\"score\\\": -0.222, \\\"completed\\\": false}\", \"{\\\"instant\\\": 52, \\\"action\\\": 3, \\\"current status\\\": [0.188, 0.927, 0.408, -0.859, 0.151, -0.209, 0.0, 0.0], \\\"score\\\": 0.085, \\\"completed\\\": false}\", \"{\\\"instant\\\": 54, \\\"action\\\": 3, \\\"current status\\\": [0.196, 0.886, 0.428, -0.909, 0.124, -0.293, 0.0, 0.0], \\\"score\\\": 0.6, \\\"completed\\\": false}\", \"{\\\"instant\\\": 56, \\\"action\\\": 3, \\\"current status\\\": [0.204, 0.844, 0.448, -0.961, 0.089, -0.373, 0.0, 0.0], \\\"score\\\": 1.15, \\\"completed\\\": false}\", \"{\\\"instant\\\": 58, \\\"action\\\": 2, \\\"current status\\\": [0.212, 0.802, 0.411, -0.92, 0.049, -0.398, 0.0, 0.0], \\\"score\\\": 4.814, \\\"completed\\\": false}\", \"{\\\"instant\\\": 60, \\\"action\\\": 2, \\\"current status\\\": [0.22, 0.762, 0.404, -0.896, 0.01, -0.4, 0.0, 0.0], \\\"score\\\": 3.758, \\\"completed\\\": false}\", \"{\\\"instant\\\": 62, \\\"action\\\": 2, \\\"current status\\\": [0.228, 0.723, 0.406, -0.851, -0.031, -0.397, 0.0, 0.0], \\\"score\\\": 1.185, \\\"completed\\\": false}\", \"{\\\"instant\\\": 64, \\\"action\\\": 2, \\\"current status\\\": [0.236, 0.685, 0.425, -0.838, -0.069, -0.383, 0.0, 0.0], \\\"score\\\": -0.001, \\\"completed\\\": false}\", \"{\\\"instant\\\": 66, \\\"action\\\": 2, \\\"current status\\\": [0.244, 0.65, 0.443, -0.773, -0.107, -0.379, 0.0, 0.0], \\\"score\\\": 1.484, \\\"completed\\\": false}\", \"{\\\"instant\\\": 68, \\\"action\\\": 1, \\\"current status\\\": [0.252, 0.613, 0.424, -0.826, -0.14, -0.301, 0.0, 0.0], \\\"score\\\": -1.738, \\\"completed\\\": false}\", \"{\\\"instant\\\": 70, \\\"action\\\": 1, \\\"current status\\\": [0.26, 0.574, 0.404, -0.878, -0.164, -0.223, 0.0, 0.0], \\\"score\\\": -1.559, \\\"completed\\\": false}\", \"{\\\"instant\\\": 72, \\\"action\\\": 1, \\\"current status\\\": [0.268, 0.533, 0.385, -0.929, -0.18, -0.143, 0.0, 0.0], \\\"score\\\": -0.924, \\\"completed\\\": false}\", \"{\\\"instant\\\": 74, \\\"action\\\": 1, \\\"current status\\\": [0.275, 0.489, 0.365, -0.981, -0.189, -0.064, 0.0, 0.0], \\\"score\\\": -0.536, \\\"completed\\\": false}\", \"{\\\"instant\\\": 76, \\\"action\\\": 1, \\\"current status\\\": [0.282, 0.444, 0.343, -1.031, -0.189, 0.027, 0.0, 0.0], \\\"score\\\": -0.157, \\\"completed\\\": false}\", \"{\\\"instant\\\": 78, \\\"action\\\": 1, \\\"current status\\\": [0.289, 0.395, 0.324, -1.082, -0.18, 0.107, 0.0, 0.0], \\\"score\\\": 0.145, \\\"completed\\\": false}\", \"{\\\"instant\\\": 80, \\\"action\\\": 1, \\\"current status\\\": [0.295, 0.345, 0.307, -1.133, -0.164, 0.175, 0.0, 0.0], \\\"score\\\": 0.363, \\\"completed\\\": false}\", \"{\\\"instant\\\": 82, \\\"action\\\": 1, \\\"current status\\\": [0.301, 0.292, 0.289, -1.186, -0.142, 0.247, 0.0, 0.0], \\\"score\\\": 0.642, \\\"completed\\\": false}\", \"{\\\"instant\\\": 84, \\\"action\\\": 1, \\\"current status\\\": [0.307, 0.237, 0.272, -1.237, -0.112, 0.316, 0.0, 0.0], \\\"score\\\": 0.809, \\\"completed\\\": false}\", \"{\\\"instant\\\": 86, \\\"action\\\": 2, \\\"current status\\\": [0.313, 0.18, 0.276, -1.265, -0.076, 0.359, 0.0, 0.0], \\\"score\\\": 2.315, \\\"completed\\\": false}\", \"{\\\"instant\\\": 88, \\\"action\\\": 2, \\\"current status\\\": [0.319, 0.124, 0.278, -1.216, -0.041, 0.352, 0.0, 0.0], \\\"score\\\": 6.353, \\\"completed\\\": false}\", \"{\\\"instant\\\": 90, \\\"action\\\": 2, \\\"current status\\\": [0.325, 0.072, 0.279, -1.165, -0.006, 0.348, 0.0, 0.0], \\\"score\\\": 3.759, \\\"completed\\\": false}\", \"{\\\"instant\\\": 92, \\\"action\\\": 2, \\\"current status\\\": [0.331, 0.02, 0.266, -1.131, 0.029, 0.335, 0.0, 0.0], \\\"score\\\": -0.539, \\\"completed\\\": false}\", \"{\\\"instant\\\": 94, \\\"action\\\": 2, \\\"current status\\\": [0.336, -0.029, 0.273, -1.081, 0.043, -0.044, 1.0, 1.0], \\\"score\\\": 14.213, \\\"completed\\\": false}\", \"{\\\"instant\\\": 95, \\\"action\\\": 2, \\\"current status\\\": [0.338, -0.05, 0.354, -0.612, 0.009, -3.432, 1.0, 1.0], \\\"score\\\": -100, \\\"completed\\\": true}\"], \"total score\": -57.13390452568175}. You have to improve the last code generated to maximize the reward. Please, make it more efficient, faster and more robust.\n",
      "2024-06-12 13:51:24,972 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/messages \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:51:24,976 - INFO - Iteration: 3\n",
      "2024-06-12 13:51:25,791 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:51:26,001 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_OIjMZIbRaLhDaHx3AmxsLFEs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:51:26,004 - INFO - Status: queued\n",
      "2024-06-12 13:51:26,302 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_OIjMZIbRaLhDaHx3AmxsLFEs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:51:46,307 - INFO - Status: queued\n",
      "2024-06-12 13:51:46,683 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_OIjMZIbRaLhDaHx3AmxsLFEs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:52:06,687 - INFO - Status: requires_action\n",
      "2024-06-12 13:52:06,690 - INFO - Arguments: {'code': 'import random\\n\\nclass LunarLanderController:\\n    def __init__(self):\\n        self.steps_without_scoring_well = 0\\n\\n    def act(self, observation):\\n        \\'\\'\\'\\n        The function that codifies the action to be taken in each instant of time.\\n\\n        Args:\\n            observation (numpy.array):\\n                \"description\": \"The state of the environment after the action is taken.\",\\n                \"positions\": {  \\n                    \"0\": \"X position\",\\n                    \"1\": \"Y position\",\\n                    \"2\": \"X velocity\",\\n                    \"3\": \"Y velocity\",\\n                    \"4\": \"Angle\",\\n                    \"5\": \"Angular velocity\",\\n                    \"6\": \"Left contact sensor\",\\n                    \"7\": \"Right contact sensor\"\\n                },\\n                \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\\n                \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\\n\\n        Returns:\\n            Integer  : The action to be taken.\\n        \\'\\'\\'\\n        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\\n\\n        # If the lunar lander has landed correctly, do nothing (action 0)\\n        if left_contact == 1 and right_contact == 1:\\n            return 0\\n\\n        # If the angle is too large, attempt to correct it\\n        if angle < -0.1:\\n            return 1  # fire right engine\\n        elif angle > 0.1:\\n            return 3  # fire left engine\\n\\n        # If the lander is moving too fast horizontally, attempt to correct it\\n        if x_vel < -0.1:\\n            return 1  # fire right engine\\n        elif x_vel > 0.1:\\n            return 3  # fire left engine\\n\\n        # If the lander is falling too fast, fire the main engine\\n        if y_vel < -0.3:\\n            return 2\\n\\n        # If the lander is not descending, start descending\\n        if y_vel >= 0:\\n            return 2  # fire main engine\\n\\n        # Increment the steps without well score\\n        self.steps_without_scoring_well += 1\\n\\n        # Edge case: if point threshold without well score perform random step\\n        if self.steps_without_scoring_well >= 7:\\n            self.steps_without_scoring_well = 0\\n            return random.randint(0, 3)\\n\\n        # Default action\\n        return 0\\n\\n# Initialize the controller instance\\nlander_controller = LunarLanderController()\\n\\n# Wrapper function to use the controller in the environment\\nget_action = lander_controller.act', 'filename': 'Action.py'}\n",
      "2024-06-12 13:52:06,692 - INFO - \n",
      "Codigo generado:\n",
      "import random\n",
      "\n",
      "class LunarLanderController:\n",
      "    def __init__(self):\n",
      "        self.steps_without_scoring_well = 0\n",
      "\n",
      "    def act(self, observation):\n",
      "        '''\n",
      "        The function that codifies the action to be taken in each instant of time.\n",
      "\n",
      "        Args:\n",
      "            observation (numpy.array):\n",
      "                \"description\": \"The state of the environment after the action is taken.\",\n",
      "                \"positions\": {  \n",
      "                    \"0\": \"X position\",\n",
      "                    \"1\": \"Y position\",\n",
      "                    \"2\": \"X velocity\",\n",
      "                    \"3\": \"Y velocity\",\n",
      "                    \"4\": \"Angle\",\n",
      "                    \"5\": \"Angular velocity\",\n",
      "                    \"6\": \"Left contact sensor\",\n",
      "                    \"7\": \"Right contact sensor\"\n",
      "                },\n",
      "                \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\n",
      "                \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\n",
      "\n",
      "        Returns:\n",
      "            Integer  : The action to be taken.\n",
      "        '''\n",
      "        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\n",
      "\n",
      "        # If the lunar lander has landed correctly, do nothing (action 0)\n",
      "        if left_contact == 1 and right_contact == 1:\n",
      "            return 0\n",
      "\n",
      "        # If the angle is too large, attempt to correct it\n",
      "        if angle < -0.1:\n",
      "            return 1  # fire right engine\n",
      "        elif angle > 0.1:\n",
      "            return 3  # fire left engine\n",
      "\n",
      "        # If the lander is moving too fast horizontally, attempt to correct it\n",
      "        if x_vel < -0.1:\n",
      "            return 1  # fire right engine\n",
      "        elif x_vel > 0.1:\n",
      "            return 3  # fire left engine\n",
      "\n",
      "        # If the lander is falling too fast, fire the main engine\n",
      "        if y_vel < -0.3:\n",
      "            return 2\n",
      "\n",
      "        # If the lander is not descending, start descending\n",
      "        if y_vel >= 0:\n",
      "            return 2  # fire main engine\n",
      "\n",
      "        # Increment the steps without well score\n",
      "        self.steps_without_scoring_well += 1\n",
      "\n",
      "        # Edge case: if point threshold without well score perform random step\n",
      "        if self.steps_without_scoring_well >= 7:\n",
      "            self.steps_without_scoring_well = 0\n",
      "            return random.randint(0, 3)\n",
      "\n",
      "        # Default action\n",
      "        return 0\n",
      "\n",
      "# Initialize the controller instance\n",
      "lander_controller = LunarLanderController()\n",
      "\n",
      "# Wrapper function to use the controller in the environment\n",
      "get_action = lander_controller.act\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call: [RequiredActionFunctionToolCall(id='call_eDwwEWqzsInZKQ9yu6ETozEu', function=Function(arguments='{\"code\":\"import random\\\\n\\\\nclass LunarLanderController:\\\\n    def __init__(self):\\\\n        self.steps_without_scoring_well = 0\\\\n\\\\n    def act(self, observation):\\\\n        \\'\\'\\'\\\\n        The function that codifies the action to be taken in each instant of time.\\\\n\\\\n        Args:\\\\n            observation (numpy.array):\\\\n                \\\\\"description\\\\\": \\\\\"The state of the environment after the action is taken.\\\\\",\\\\n                \\\\\"positions\\\\\": {  \\\\n                    \\\\\"0\\\\\": \\\\\"X position\\\\\",\\\\n                    \\\\\"1\\\\\": \\\\\"Y position\\\\\",\\\\n                    \\\\\"2\\\\\": \\\\\"X velocity\\\\\",\\\\n                    \\\\\"3\\\\\": \\\\\"Y velocity\\\\\",\\\\n                    \\\\\"4\\\\\": \\\\\"Angle\\\\\",\\\\n                    \\\\\"5\\\\\": \\\\\"Angular velocity\\\\\",\\\\n                    \\\\\"6\\\\\": \\\\\"Left contact sensor\\\\\",\\\\n                    \\\\\"7\\\\\": \\\\\"Right contact sensor\\\\\"\\\\n                },\\\\n                \\\\\"min_values\\\\\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\\\\n                \\\\\"max_values\\\\\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\\\\n\\\\n        Returns:\\\\n            Integer  : The action to be taken.\\\\n        \\'\\'\\'\\\\n        x_pos, y_pos, x_vel, y_vel, angle, ang_vel, left_contact, right_contact = observation\\\\n\\\\n        # If the lunar lander has landed correctly, do nothing (action 0)\\\\n        if left_contact == 1 and right_contact == 1:\\\\n            return 0\\\\n\\\\n        # If the angle is too large, attempt to correct it\\\\n        if angle < -0.1:\\\\n            return 1  # fire right engine\\\\n        elif angle > 0.1:\\\\n            return 3  # fire left engine\\\\n\\\\n        # If the lander is moving too fast horizontally, attempt to correct it\\\\n        if x_vel < -0.1:\\\\n            return 1  # fire right engine\\\\n        elif x_vel > 0.1:\\\\n            return 3  # fire left engine\\\\n\\\\n        # If the lander is falling too fast, fire the main engine\\\\n        if y_vel < -0.3:\\\\n            return 2\\\\n\\\\n        # If the lander is not descending, start descending\\\\n        if y_vel >= 0:\\\\n            return 2  # fire main engine\\\\n\\\\n        # Increment the steps without well score\\\\n        self.steps_without_scoring_well += 1\\\\n\\\\n        # Edge case: if point threshold without well score perform random step\\\\n        if self.steps_without_scoring_well >= 7:\\\\n            self.steps_without_scoring_well = 0\\\\n            return random.randint(0, 3)\\\\n\\\\n        # Default action\\\\n        return 0\\\\n\\\\n# Initialize the controller instance\\\\nlander_controller = LunarLanderController()\\\\n\\\\n# Wrapper function to use the controller in the environment\\\\nget_action = lander_controller.act\",\"filename\":\"Action.py\"}', name='store_code_in_file'), type='function')]\n",
      "Moviepy - Building video c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_3.mp4\\rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_3.mp4\\rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready c:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\video\\iteration_3.mp4\\rl-video-episode-0.mp4\n",
      "Número de instantes: 97. Tamaño de logs: 49\n",
      "episode  1 score -57.134 avg score -0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:52:11,079 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_OIjMZIbRaLhDaHx3AmxsLFEs/submit_tool_outputs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:52:11,083 - INFO - Compilación exitosa.\n",
      "2024-06-12 13:52:11,084 - INFO - Status: requires_action\n",
      "2024-06-12 13:52:11,359 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_OIjMZIbRaLhDaHx3AmxsLFEs \"HTTP/1.1 200 OK\"\n",
      "2024-06-12 13:52:31,363 - INFO - Status: in_progress\n",
      "2024-06-12 13:52:31,737 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_gbvjHCucINWnSa31LlCYO66U/runs/run_OIjMZIbRaLhDaHx3AmxsLFEs \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "DESCRIPTION = \"You are an expert programer in Pyhton. Your specialty is to generate the code responsible for making decisions about actions to be taken in various spacecraft landing environments.The objective is to land the spacecraft within a target zone in the shortest possible time and very gently. A scoring system is used to evaluate the landings, which must be maximized.\"\n",
    "INSTRUCTIONS = f\"\"\"Your task is:\n",
    "1. Analyze and reason about the results received in the last landing attempts.\n",
    "2. Your goal is to be able to make the appropriate decision based on the results of previous iterations. You must code the decision making based on your reasoning in a Python function.\n",
    "3. Based on the logs you should improve the code generated in the 'act' function in the last iteration, seeking to maximize the score received and generate a higher quality code.\n",
    "4. Save the code of the act function in the file 'Action.py' using the tools given.\n",
    "5. Improve your results and correct any errors you may have generated in your last code if they exist.\n",
    "\"\"\"\n",
    "NAME = \"Spacecraft Landing Master\"\n",
    "\n",
    "initial_msg = f\"Take a deep breath and think step by step. This is the record of an example of a successful landing in this environment, but under other conditions: {success_logs}. This is the code of the initial function: {agent_initial_code} and these are the execution logs of one landing attempt: {initial_logs}. Analyze the results and improve the code.\"\n",
    "\n",
    "logger = configura_log('Spacecraft_4o_commits_recorder.log')\n",
    "response = create_and_run_llm_loop(initial_msg, logger, model=\"gpt-4o\", num_iterations=5)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "* Incluir guardado de vídeo.\n",
    "* Mejorar el prompt inicial.\n",
    "* Incluir ejemplos positivos.\n",
    "* Incluir cambios en el código con GIT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
