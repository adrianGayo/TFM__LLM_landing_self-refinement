{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "from Assistant import AssistantOpenAI\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from git import Repo\n",
    "\n",
    "import numpy as np\n",
    "#from collections import deque, namedtuple\n",
    "\n",
    "# For visualization\n",
    "import gymnasium.wrappers.record_video as record_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 200\n",
    "ENV_NAME = 'LunarLander-v2'\n",
    "ARCLABKEY_OPENAI = \"sk-proj-DvHDR3hpgbm2r3kCA9jKT3BlbkFJL57ABXkfaWAIYKBxdhM6\"\n",
    "ARCLABKEY_OPENAI = \"sk-proj-GvaDXazpibWA2M1I5Pu2T3BlbkFJxDuKlr9AcoVG98ctJZ7Q\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function calling.\n",
    "\n",
    "Función encargada de almacenar el código generado mediante la opción de function calling del asistente de OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_code_in_file(code, filename):\n",
    "    \"\"\" Store code in a file\n",
    "    \n",
    "    Args:\n",
    "        code: str: code to store\n",
    "        filename: str: filename to store code in\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(code)\n",
    "        \n",
    "store_code_in_file_schema = {\n",
    "    \"name\": \"store_code_in_file\",\n",
    "    \"description\": \"Store code in a file\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"code\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The Python code to store.\"\n",
    "            },\n",
    "            \"filename\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The filename to store the code in.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"code\", \"filename\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "TOOLS = [{\"type\": \"function\", \"function\": store_code_in_file_schema}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entorno Lunnar Lander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_initial_code = \"\"\"\n",
    "import random\n",
    "\n",
    "def act(observation):\n",
    "    '''\n",
    "    The function that codifies the action to be taken in each instant of time.\n",
    "\n",
    "    Args:\n",
    "        observation (numpy.array):\n",
    "            \"description\": \"The state of the environment after the action is taken.\",\n",
    "            \"positions\": {  \n",
    "                \"0\": \"X position\",\n",
    "                \"1\": \"Y position\",\n",
    "                \"2\": \"X velocity\",\n",
    "                \"3\": \"Y velocity\",\n",
    "                \"4\": \"Angle\",\n",
    "                \"5\": \"Angular velocity\",\n",
    "                \"6\": \"Left contact sensor\",\n",
    "                \"7\": \"Right contact sensor\"\n",
    "            },\n",
    "            \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\n",
    "            \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1]\n",
    "\n",
    "    Returns:\n",
    "        Integer  : The action to be taken.\n",
    "        \"options\": {\n",
    "                '0' : \"Switch off engines\",\n",
    "                '1' : \"Push left engine\",\n",
    "                '2' : \"Push both engines (upwards)\",\n",
    "                '3' : \"Push right engine\"\n",
    "            }\n",
    "    '''\n",
    "    return random.randint(0, 3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapeador de logs a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_description = {\n",
    "    \"description\": \"Log data for each step of the spacecraft landing environment.\",\n",
    "    \"landing attempt\": {\n",
    "        \"type\": \"integer\",\n",
    "        \"description\": \"The episode number.\"\n",
    "    },\n",
    "    \"logs\": {\n",
    "        \"time\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The instant within the landing attempt where the current log is taken.\"\n",
    "        },\n",
    "        \"action\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The possible actions taken.\",\n",
    "            \"options\": {\n",
    "                '0' : \"Switch off engines\",\n",
    "                '1' : \"Push left engine\",\n",
    "                '2' : \"Push both engines (upwards)\",\n",
    "                '3' : \"Push right engine\"\n",
    "            }\n",
    "        },  \n",
    "        \"current status\": {\n",
    "            \"type\": \"array\",\n",
    "            \"description\": \"The state of the environment after the action is taken.\",\n",
    "            \"positions\": {  \n",
    "                \"0\": {\n",
    "                    \"name\": \"X position\",\n",
    "                    \"description\": \"The horizontal position of the spacecraft relative to the landing zone.\"\n",
    "                },\n",
    "                \"1\": {\n",
    "                    \"name\": \"Y position\",\n",
    "                    \"description\": \"The vertical position of the spacecraft relative to the landing zone.\"\n",
    "                },\n",
    "                \"2\": {\n",
    "                    \"name\": \"X velocity\",\n",
    "                    \"description\": \"The horizontal velocity of the spacecraft.\"\n",
    "                },\n",
    "                \"3\": {\n",
    "                    \"name\": \"Y velocity\",\n",
    "                    \"description\": \"The vertical velocity of the spacecraft.\"\n",
    "                },\n",
    "                \"4\": {\n",
    "                    \"name\": \"Angle\",\n",
    "                    \"description\": \"The angle of the spacecraft relative to the vertical (left negative, right positive).\"\n",
    "                },\n",
    "                \"5\": {\n",
    "                    \"name\": \"Angular velocity\",\n",
    "                    \"description\": \"The rate of change of the angle of the spacecraft.\"\n",
    "                },\n",
    "                \"6\": {\n",
    "                    \"name\": \"Left contact sensor with landing zone\",\n",
    "                    \"description\": \"Indicates whether the left side of the spacecraft is in contact with the landing zone.\"\n",
    "                },\n",
    "                \"7\": {\n",
    "                    \"name\": \"Right contact sensor with landing zone\",\n",
    "                    \"description\": \"Indicates whether the right side of the spacecraft is in contact with the landing zone.\"\n",
    "                }\n",
    "            },\n",
    "            \"min_values\": [-1.5, -1.5, -5.0, -5.0, -3.14, -5.0, 0, 0],\n",
    "            \"max_values\": [1.5, 1.5, 5.0, 5.0, 3.14, 5.0, 1, 1],\n",
    "            \n",
    "        }, \n",
    "        \"score\": {\n",
    "            \"type\": \"number\",\n",
    "            \"description\": \"The score received for the action.\"\n",
    "        },  \n",
    "        \"completed\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"Whether the landing event has ended (landing or accident).\"\n",
    "        }\n",
    "    },\n",
    "    \"total score\": {\n",
    "        \"type\": \"number\",\n",
    "        \"description\": \"The total score received for the landing attempt.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_step_data(instant, action, next_state, reward, terminated):\n",
    "    \"\"\" Format the step data into a JSON string\n",
    "    \n",
    "    Args:\n",
    "        instant: int: the instant within the landing attempt where the current log is taken\n",
    "        action: int: the action taken\n",
    "        next_state: np.array: the next state of the environment\n",
    "        reward: float: the reward received\n",
    "        terminated: bool: whether the landing event has ended\n",
    "        \n",
    "    Returns:\n",
    "        str: the step data formatted as a JSON string\n",
    "    \"\"\"\n",
    "    # Convertir el array numpy a una lista\n",
    "    next_state_list = next_state.tolist()\n",
    "\n",
    "    # Redondear los elementos de la lista a 4 decimales\n",
    "    next_state_list_rounded = [round(x, 3) for x in next_state_list]\n",
    "\n",
    "    step_data = {\n",
    "        'time': instant,\n",
    "        'action' : int(action),\n",
    "        'current status': next_state_list_rounded,  # Convert numpy array to list\n",
    "        'score': round(reward, 3),\n",
    "        #'completed': terminated,\n",
    "        #'truncated': truncated\n",
    "        #'info': info\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a JSON string\n",
    "    #step_data_json = json.dumps(step_data)\n",
    "\n",
    "    return step_data\n",
    "\n",
    "\n",
    "def format_episode_logs(logs, episode, total_score):\n",
    "    \"\"\" Format the logs into a JSON string\n",
    "    \n",
    "    Args:\n",
    "        logs: list: the logs for each step of the environment\n",
    "        episode: int: the episode number\n",
    "        \n",
    "    Returns:\n",
    "        str: the logs formatted as a JSON string\n",
    "    \"\"\"\n",
    "    logs_data = {\n",
    "        'landing attempt': episode,\n",
    "        'logs': logs,\n",
    "        'total score': round(total_score, 3)\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a JSON string\n",
    "    logs_json = json.dumps(logs_data)\n",
    "\n",
    "    return logs_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_changes(repo_path, commit_message):\n",
    "    \"\"\" Commit changes to the repository.\n",
    "\n",
    "    Args:\n",
    "        repo_path (str): Path to the repository.\n",
    "        commit_message (str): The commit message.\n",
    "    \"\"\"\n",
    "    repo = Repo(repo_path)\n",
    "    repo.git.add(update=True)\n",
    "    repo.index.commit(commit_message)\n",
    "    origin = repo.remote(name='origin')\n",
    "    origin.push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código encargado de ejecutar los eventos en el entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Action\n",
    "\n",
    "def lunar_lander(max_t=1000, n_games=1, display=False, seed=38, agent=None, recoder=False, video_filename='video/video.mp4'):\n",
    "    \"\"\" Run the Lunar Lander environment\n",
    "    \n",
    "    Args:\n",
    "        max_t: int: the maximum number of timesteps\n",
    "        n_games: int: the number of games to play\n",
    "        display: bool: whether to display the environment\n",
    "        seed: int: the seed for the environment\n",
    "        agent: object: the agent to use\n",
    "        recoder: bool: whether to record the video\n",
    "        video_filename: str: the filename for the video\n",
    "        \n",
    "    Returns:\n",
    "        str: the logs for the landing attempts\n",
    "    \"\"\"\n",
    "    \n",
    "    # Incluimos la opción del entorno gráfico y la de grabación.\n",
    "    if display:\n",
    "        env = gym.make(ENV_NAME, render_mode='human')\n",
    "        if recoder:\n",
    "            env = gym.make(ENV_NAME, render_mode='rgb_array')\n",
    "            env.reset() \n",
    "            video_recorder = record_video.RecordVideo(env, video_filename)\n",
    "    else:\n",
    "        env = gym.make(ENV_NAME)\n",
    "\n",
    "    # Bucle principal de ejecución de los episodios.\n",
    "    logs = []\n",
    "    for episode in range(1, n_games+1):\n",
    "        # Revisamos que la semilla sea un número entero o una lista de semillas.\n",
    "        if isinstance(seed, list):\n",
    "            semilla = seed[episode-1]\n",
    "        else:\n",
    "            semilla = seed\n",
    "        print(f\"Semilla {semilla}\")    \n",
    "        state = env.reset(seed=semilla) # Set a seed for the environment\n",
    "        state = state[0] # Eliminamos el diccionario vacio y dejamos unicamente el estado de 8 elementos.\n",
    "        score = 0\n",
    "        instant = 0\n",
    "        episode_actions = []\n",
    "        if recoder: # En caso de que se quiera grabar el video, se inicia el grabador.\n",
    "            video_recorder.start_video_recorder()\n",
    "            \n",
    "        for i in range(max_t): # Bucle de ejecución de los instantes de tiempo.\n",
    "            \n",
    "            # Seleccionamos el método de elegir la acción (agente exitoso o método de decisión del asistente)\n",
    "            if agent: \n",
    "                action = agent.act(state)\n",
    "            else:\n",
    "                action = Action.act(state)\n",
    "            \n",
    "            # Avanzamos un instante de tiempo en el entorno en función de si se quiere grabar el video o no.\n",
    "            if recoder:\n",
    "                next_state, reward, terminated, truncated, info = video_recorder.step(action)\n",
    "            else:\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "            # Formateamos los datos del instante de tiempo y los alcenamos.\n",
    "            json_logs = format_step_data(instant, action, next_state, reward, terminated)\n",
    "            score += reward\n",
    "            instant += 1\n",
    "            if len(episode_actions) < 20 or len(episode_actions) % 2 == 0 or terminated:\n",
    "                logs.append(json_logs)\n",
    "            #logs.append(json_logs)\n",
    "            episode_actions.append(action)\n",
    "            state = next_state\n",
    "            if terminated: # Condición de salida del bucle, si el episodio ha terminado.\n",
    "                break\n",
    "        json_episode_logs = format_episode_logs(logs, episode, score) \n",
    "        \n",
    "        print(f\"Número de instantes: {instant+1}. Tamaño de logs: {len(logs)}\")\n",
    "        print('episode ', episode, 'score %.3f' % float(score), 'avg score %.3f' % (float(score) / instant))\n",
    "        \n",
    "    if recoder:\n",
    "        video_recorder.close()\n",
    "    else:\n",
    "        env.close()\n",
    "        \n",
    "    return json_episode_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs del código inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semilla 38\n",
      "Número de instantes: 99. Tamaño de logs: 60\n",
      "episode  1 score -291.906 avg score -2.979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"landing attempt\": 1, \"logs\": [{\"time\": 0, \"action\": 2, \"current status\": [0.007, 1.418, 0.377, 0.172, -0.009, -0.089, 0.0, 0.0], \"score\": -1.45}, {\"time\": 1, \"action\": 3, \"current status\": [0.011, 1.422, 0.389, 0.145, -0.016, -0.135, 0.0, 0.0], \"score\": -1.061}, {\"time\": 2, \"action\": 3, \"current status\": [0.015, 1.424, 0.399, 0.119, -0.024, -0.177, 0.0, 0.0], \"score\": -1.33}, {\"time\": 3, \"action\": 2, \"current status\": [0.019, 1.428, 0.391, 0.145, -0.034, -0.187, 0.0, 0.0], \"score\": -1.581}, {\"time\": 4, \"action\": 2, \"current status\": [0.023, 1.431, 0.395, 0.148, -0.043, -0.184, 0.0, 0.0], \"score\": -2.07}, {\"time\": 5, \"action\": 0, \"current status\": [0.027, 1.434, 0.395, 0.121, -0.052, -0.184, 0.0, 0.0], \"score\": -0.345}, {\"time\": 6, \"action\": 2, \"current status\": [0.031, 1.437, 0.391, 0.134, -0.062, -0.192, 0.0, 0.0], \"score\": -1.543}, {\"time\": 7, \"action\": 3, \"current status\": [0.034, 1.439, 0.4, 0.107, -0.073, -0.227, 0.0, 0.0], \"score\": -1.477}, {\"time\": 8, \"action\": 3, \"current status\": [0.038, 1.441, 0.408, 0.08, -0.086, -0.263, 0.0, 0.0], \"score\": -1.776}, {\"time\": 9, \"action\": 1, \"current status\": [0.042, 1.442, 0.399, 0.053, -0.097, -0.224, 0.0, 0.0], \"score\": 0.101}, {\"time\": 10, \"action\": 0, \"current status\": [0.046, 1.443, 0.399, 0.026, -0.109, -0.224, 0.0, 0.0], \"score\": -0.93}, {\"time\": 11, \"action\": 1, \"current status\": [0.05, 1.443, 0.391, 0.0, -0.118, -0.193, 0.0, 0.0], \"score\": -0.173}, {\"time\": 12, \"action\": 3, \"current status\": [0.054, 1.442, 0.4, -0.027, -0.13, -0.23, 0.0, 0.0], \"score\": -2.143}, {\"time\": 13, \"action\": 2, \"current status\": [0.058, 1.442, 0.423, -0.008, -0.141, -0.217, 0.0, 0.0], \"score\": -3.549}, {\"time\": 14, \"action\": 2, \"current status\": [0.062, 1.442, 0.426, -0.001, -0.152, -0.221, 0.0, 0.0], \"score\": -1.685}, {\"time\": 15, \"action\": 2, \"current status\": [0.066, 1.442, 0.441, 0.004, -0.162, -0.213, 0.0, 0.0], \"score\": -2.935}, {\"time\": 16, \"action\": 3, \"current status\": [0.071, 1.442, 0.449, -0.024, -0.175, -0.247, 0.0, 0.0], \"score\": -2.117}, {\"time\": 17, \"action\": 1, \"current status\": [0.075, 1.44, 0.438, -0.05, -0.185, -0.202, 0.0, 0.0], \"score\": -0.057}, {\"time\": 18, \"action\": 2, \"current status\": [0.079, 1.439, 0.437, -0.044, -0.195, -0.212, 0.0, 0.0], \"score\": -1.135}, {\"time\": 19, \"action\": 1, \"current status\": [0.084, 1.438, 0.428, -0.069, -0.204, -0.173, 0.0, 0.0], \"score\": -0.193}, {\"time\": 20, \"action\": 0, \"current status\": [0.088, 1.436, 0.428, -0.096, -0.213, -0.173, 0.0, 0.0], \"score\": -1.187}, {\"time\": 22, \"action\": 0, \"current status\": [0.096, 1.43, 0.436, -0.15, -0.233, -0.204, 0.0, 0.0], \"score\": -1.518}, {\"time\": 24, \"action\": 1, \"current status\": [0.105, 1.421, 0.437, -0.205, -0.256, -0.211, 0.0, 0.0], \"score\": -0.911}, {\"time\": 26, \"action\": 3, \"current status\": [0.114, 1.411, 0.455, -0.238, -0.279, -0.251, 0.0, 0.0], \"score\": -2.912}, {\"time\": 28, \"action\": 2, \"current status\": [0.123, 1.401, 0.465, -0.232, -0.305, -0.267, 0.0, 0.0], \"score\": -1.636}, {\"time\": 30, \"action\": 2, \"current status\": [0.132, 1.39, 0.501, -0.246, -0.336, -0.297, 0.0, 0.0], \"score\": -3.079}, {\"time\": 32, \"action\": 1, \"current status\": [0.142, 1.377, 0.48, -0.295, -0.359, -0.207, 0.0, 0.0], \"score\": -0.707}, {\"time\": 34, \"action\": 2, \"current status\": [0.151, 1.362, 0.515, -0.327, -0.382, -0.226, 0.0, 0.0], \"score\": -3.221}, {\"time\": 36, \"action\": 2, \"current status\": [0.162, 1.347, 0.544, -0.32, -0.401, -0.189, 0.0, 0.0], \"score\": -1.994}, {\"time\": 38, \"action\": 1, \"current status\": [0.172, 1.331, 0.534, -0.37, -0.418, -0.148, 0.0, 0.0], \"score\": -0.58}, {\"time\": 40, \"action\": 3, \"current status\": [0.183, 1.313, 0.552, -0.429, -0.438, -0.226, 0.0, 0.0], \"score\": -2.89}, {\"time\": 42, \"action\": 1, \"current status\": [0.194, 1.292, 0.553, -0.482, -0.463, -0.233, 0.0, 0.0], \"score\": -0.988}, {\"time\": 44, \"action\": 2, \"current status\": [0.206, 1.27, 0.62, -0.483, -0.491, -0.274, 0.0, 0.0], \"score\": -3.076}, {\"time\": 46, \"action\": 1, \"current status\": [0.218, 1.246, 0.612, -0.533, -0.517, -0.232, 0.0, 0.0], \"score\": -0.973}, {\"time\": 48, \"action\": 0, \"current status\": [0.23, 1.221, 0.605, -0.584, -0.536, -0.198, 0.0, 0.0], \"score\": -1.645}, {\"time\": 50, \"action\": 0, \"current status\": [0.242, 1.193, 0.614, -0.641, -0.561, -0.245, 0.0, 0.0], \"score\": -1.845}, {\"time\": 52, \"action\": 1, \"current status\": [0.254, 1.162, 0.611, -0.693, -0.587, -0.232, 0.0, 0.0], \"score\": -0.867}, {\"time\": 54, \"action\": 0, \"current status\": [0.266, 1.13, 0.611, -0.747, -0.61, -0.232, 0.0, 0.0], \"score\": -1.719}, {\"time\": 56, \"action\": 0, \"current status\": [0.278, 1.095, 0.604, -0.797, -0.629, -0.194, 0.0, 0.0], \"score\": -1.496}, {\"time\": 58, \"action\": 1, \"current status\": [0.29, 1.057, 0.601, -0.848, -0.649, -0.178, 0.0, 0.0], \"score\": -0.516}, {\"time\": 60, \"action\": 2, \"current status\": [0.302, 1.018, 0.618, -0.879, -0.668, -0.186, 0.0, 0.0], \"score\": -0.74}, {\"time\": 62, \"action\": 3, \"current status\": [0.314, 0.976, 0.627, -0.937, -0.689, -0.238, 0.0, 0.0], \"score\": -2.533}, {\"time\": 64, \"action\": 1, \"current status\": [0.327, 0.934, 0.651, -0.968, -0.71, -0.194, 0.0, 0.0], \"score\": -0.683}, {\"time\": 66, \"action\": 3, \"current status\": [0.34, 0.889, 0.652, -1.021, -0.728, -0.196, 0.0, 0.0], \"score\": -2.134}, {\"time\": 68, \"action\": 3, \"current status\": [0.353, 0.842, 0.691, -1.063, -0.748, -0.228, 0.0, 0.0], \"score\": -2.167}, {\"time\": 70, \"action\": 0, \"current status\": [0.367, 0.794, 0.716, -1.087, -0.772, -0.24, 0.0, 0.0], \"score\": -1.493}, {\"time\": 72, \"action\": 3, \"current status\": [0.382, 0.743, 0.73, -1.149, -0.803, -0.33, 0.0, 0.0], \"score\": -2.589}, {\"time\": 74, \"action\": 2, \"current status\": [0.397, 0.691, 0.814, -1.151, -0.836, -0.328, 0.0, 0.0], \"score\": -1.434}, {\"time\": 76, \"action\": 1, \"current status\": [0.413, 0.638, 0.799, -1.193, -0.86, -0.225, 0.0, 0.0], \"score\": -0.713}, {\"time\": 78, \"action\": 0, \"current status\": [0.429, 0.583, 0.799, -1.246, -0.883, -0.225, 0.0, 0.0], \"score\": -1.547}, {\"time\": 80, \"action\": 0, \"current status\": [0.445, 0.525, 0.807, -1.306, -0.911, -0.28, 0.0, 0.0], \"score\": -1.906}, {\"time\": 82, \"action\": 3, \"current status\": [0.462, 0.465, 0.856, -1.356, -0.94, -0.308, 0.0, 0.0], \"score\": -2.937}, {\"time\": 84, \"action\": 0, \"current status\": [0.479, 0.403, 0.851, -1.405, -0.966, -0.269, 0.0, 0.0], \"score\": -2.173}, {\"time\": 86, \"action\": 3, \"current status\": [0.496, 0.338, 0.863, -1.471, -1.001, -0.376, 0.0, 0.0], \"score\": -3.823}, {\"time\": 88, \"action\": 1, \"current status\": [0.514, 0.271, 0.904, -1.501, -1.036, -0.316, 0.0, 0.0], \"score\": -2.14}, {\"time\": 90, \"action\": 0, \"current status\": [0.532, 0.202, 0.91, -1.56, -1.072, -0.364, 0.0, 0.0], \"score\": -3.607}, {\"time\": 92, \"action\": 3, \"current status\": [0.55, 0.131, 0.908, -1.612, -1.106, -0.355, 0.0, 0.0], \"score\": -4.665}, {\"time\": 94, \"action\": 3, \"current status\": [0.568, 0.058, 0.942, -1.655, -1.144, -0.408, 0.0, 0.0], \"score\": -5.487}, {\"time\": 96, \"action\": 3, \"current status\": [0.589, -0.017, 1.021, -1.688, -1.197, -0.568, 1.0, 0.0], \"score\": -6.517}, {\"time\": 97, \"action\": 1, \"current status\": [0.6, -0.029, 1.24, -0.67, -1.534, -7.002, 1.0, 0.0], \"score\": -100}], \"total score\": -291.906}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_logs = lunar_lander(n_games=1, display=True)\n",
    "initial_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logs exitosos\n",
    "Utilizar otras semillas para que no memorice el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mDuelingDQN\u001b[39;00m\n\u001b[0;32m      3\u001b[0m agent \u001b[38;5;241m=\u001b[39m DuelingDQN\u001b[38;5;241m.\u001b[39mAgent(num_observaciones\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, num_acciones\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, red_modelo\u001b[38;5;241m=\u001b[39mDuelingDQN\u001b[38;5;241m.\u001b[39mDuelingQNetwork, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Cargamos los pesos del agente entrenado.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\\DuelingDQN.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adria\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:533\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(_C):\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    535\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import DuelingDQN\n",
    "\n",
    "agent = DuelingDQN.Agent(num_observaciones=8, num_acciones=4, red_modelo=DuelingDQN.DuelingQNetwork, seed=0)\n",
    "# Cargamos los pesos del agente entrenado.\n",
    "agent.load_weights('checkpoint_Dueling.pth')\n",
    "\n",
    "seeds = [130, 412]\n",
    "\n",
    "success_logs = lunar_lander(n_games=len(seeds), display=True, seed=seeds, agent=agent)\n",
    "success_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucle iterativo\n",
    "\n",
    "Sección principal del código encargada de conectar con el asistente de la API de OpenAI e iterar en la generación de código nuevo a partir de los registros del generado previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback, importlib\n",
    "import Action\n",
    "\n",
    "Action = importlib.reload(Action)\n",
    "\n",
    "def create_and_run_llm_loop(Incial_msg, logger, model=\"gpt-3.5-turbo\", num_iterations=10):\n",
    "    \n",
    "    agente = AssistantOpenAI(ARCLABKEY_OPENAI)\n",
    "\n",
    "    # Crea un asistente\n",
    "    asistente = agente.create_assistant(model=model, description=DESCRIPTION, instructions=INSTRUCTIONS, name=NAME, tools=TOOLS)\n",
    "    \n",
    "    # Crea un hilo\n",
    "    hilo = agente.create_thread()\n",
    "    \n",
    "    # Añade un mensaje inicial al hilo.\n",
    "    msg = agente.add_message(hilo.id, role=\"user\", content=Incial_msg)\n",
    "\n",
    "    # Bucle de aprendizaje del asistente.\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        logger.info(f\"Iteration: {i+1}\")\n",
    "        compiled = False\n",
    "\n",
    "        # Si en la presente iteración no se ha compilado el código, se pide al asistente corregir los errores antes de iterar.\n",
    "        while not compiled:\n",
    "            # Ejecuta el hilo\n",
    "            ejecucion = agente.run(hilo.id, asistente.id, tool_choice='required')\n",
    "            response = agente.get_run(ejecucion.id, hilo.id)\n",
    "\n",
    "            # Esperamos a que la respuesta esté lista.\n",
    "            while response.status not in [\"completed\", \"failed\", \"requires_action\"]:\n",
    "                logger.info(f\"Status: {ejecucion.status}\")\n",
    "                response = agente.get_run(ejecucion.id, hilo.id)\n",
    "                time.sleep(20)\n",
    "\n",
    "            # Descomponemos los elementos de la respuesta.\n",
    "            logger.info(f\"Status: {response.status}\")\n",
    "            if response.status == \"completed\":\n",
    "                return response\n",
    "            tool_call = response.required_action.submit_tool_outputs.tool_calls\n",
    "            print(f\"Tool call: {tool_call}\")\n",
    "\n",
    "            # Convierte el string a un diccionario\n",
    "            code_dict = json.loads(tool_call[0].function.arguments)\n",
    "            logger.info(f\"Arguments: {code_dict}\")\n",
    "            \n",
    "            # Obtén el código Python de la llamada a la herramienta\n",
    "            code = code_dict[\"code\"]\n",
    "            filename = code_dict[\"filename\"]  \n",
    "\n",
    "            logger.info(f\"\\nCodigo generado:\\n{code}\")\n",
    "\n",
    "            # Ejecuta el código Python\n",
    "            try:\n",
    "                store_code_in_file(code, filename)\n",
    "                time.sleep(1) # Pequeño retraso para que el sistema operativo pueda reflejar los cambios en el archivo\n",
    "                \n",
    "                # Hacemos commit de los cambios en el repositorio para analizar las modificaciones del agente.\n",
    "                commit_changes(r\"C:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\", f\"4o. Iteración {i+1}.\") \n",
    "                \n",
    "                importlib.reload(Action) # Recargamos el módulo de acciones para que se actualice con las modificaciones del agente.\n",
    "\n",
    "                # Ejecutamos el código generado.\n",
    "                logs = lunar_lander(n_games=1, display=True, recoder=True, video_filename=f\"video/iteration_{i+1}.mp4\")\n",
    "                \n",
    "                # Devolvemos la respuesta al asistente.\n",
    "                for call in tool_call:\n",
    "                    agente.devolver_respuesta(response.id, hilo.id, tool_outputs=[{\"tool_call_id\": call.id, \"output\": \"Run successful.\"}])            \n",
    "                compiled = True\n",
    "                logger.info(f\"Compilación exitosa.\")\n",
    "                \n",
    "                # Esperamos a que el agente esté listo para recibir mensajes y le añadimos el resultado de la iteración.\n",
    "                while response.status not in [\"completed\", \"failed\", \"expired\"]:\n",
    "                    logger.info(f\"Status: {response.status}\")\n",
    "                    response = agente.get_run(response.id, hilo.id)\n",
    "                    time.sleep(20)\n",
    "                \n",
    "                msg = f\"\"\"These are the logs generated by your last code: {logs}. Analyze the performance of the spacecraft and how it differs from the desired result. Be guided by the scoring system. Identify the cause of errors in your code and modify it without fear of making major changes. Think deeply about the priorities of your code and how to order and combine them correctly to achieve success.\"\"\"\n",
    "                logger.info(msg)    \n",
    "                agente.add_message(hilo.id, role=\"user\", content=msg)\n",
    "            \n",
    "            # Alimentamos el asistente con el error generado en la ejecución del código.    \n",
    "            except Exception as e:\n",
    "                logger.exception(\"Error: %s\", e)\n",
    "                error_trace = traceback.format_exc()\n",
    "                for call in tool_call:\n",
    "                    agente.devolver_respuesta(response.id, hilo.id, tool_outputs=[{\"tool_call_id\": call.id, \"output\": \"ERROR.\"}]) \n",
    "                logger.error(f\"Error: {e}.\")\n",
    "                while response.status not in [\"completed\", \"failed\", \"expired\"]:\n",
    "                    logger.info(f\"Status: {response.status}\")\n",
    "                    response = agente.get_run(ejecucion.id, hilo.id)\n",
    "                    time.sleep(30)\n",
    "                msg = f\"The code generated has an error. Please, try again. Error: {e}. Trace: {error_trace}\"   \n",
    "                logger.error(msg)   \n",
    "                agente.add_message(hilo.id, role=\"assistant\", content=msg)\n",
    "    \n",
    "    agente.mostrar_mensajes(hilo.id)  \n",
    "    vaciar_agente(agente)\n",
    "    \n",
    "    logger.info(\"\\nEjecución finalizada.\\n\\n\")       \n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def vaciar_agente(agente):\n",
    "    for assistant in agente.assistants:\n",
    "        agente.delete_assistant(assistant)\n",
    "\n",
    "    for thread in agente.threads:\n",
    "        agente.delete_thread(thread)\n",
    "        \n",
    "    print(\"Asistente vaciado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configura_log(nombre_archivo):\n",
    "    \"\"\" \n",
    "    Configura el logger para que guarde los logs en un archivo y los muestre en la consola.\n",
    "    \n",
    "    Args:\n",
    "        nombre_archivo: str Nombre del archivo donde se guardarán los logs.\n",
    "        \n",
    "    Returns:\n",
    "        logger: logging.Logger Objeto logger configurado.\n",
    "    \"\"\"\n",
    "    # Crear la carpeta logs si no existe\n",
    "    if not os.path.exists('logs'):\n",
    "        os.makedirs('logs')\n",
    "    # Configura el logger\n",
    "    logging.basicConfig(filename=f'logs/{nombre_archivo}', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    # Añade un StreamHandler para mostrar los logs en la consola\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución con el asistente\n",
    "\n",
    "Prompt inicial y mensajes del sistema para el asistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 12:54:05,317 - INFO - HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 12:54:05,646 - INFO - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 12:54:06,026 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_FjycrwXuowzQlfTMVUsY8mbR/messages \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 12:54:06,291 - INFO - Iteration: 1\n",
      "2024-06-25 12:54:06,868 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_FjycrwXuowzQlfTMVUsY8mbR/runs \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 12:54:07,209 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_FjycrwXuowzQlfTMVUsY8mbR/runs/run_CdSA0VbpnhkVlAkUyMCR3kcT \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 12:54:07,216 - INFO - Status: queued\n",
      "2024-06-25 12:54:07,427 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_FjycrwXuowzQlfTMVUsY8mbR/runs/run_CdSA0VbpnhkVlAkUyMCR3kcT \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m initial_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the record of an example of a successful landing in this environment, but under other conditions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuccess_logs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You have to be able to learn from it to land successfully with any other conditions. This is the code of the initial function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_initial_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and these are the execution logs of one landing attempt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_logs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.Take a deep breath and reason step-by-step. After reasoning analyze the results, learn and make better code.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m logger \u001b[38;5;241m=\u001b[39m configura_log(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpacecraft_4o_betterprompt.log\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m create_and_run_llm_loop(initial_msg, logger, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m, in \u001b[0;36mcreate_and_run_llm_loop\u001b[1;34m(Incial_msg, logger, model, num_iterations)\u001b[0m\n\u001b[0;32m     33\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mejecucion\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m     response \u001b[38;5;241m=\u001b[39m agente\u001b[38;5;241m.\u001b[39mget_run(ejecucion\u001b[38;5;241m.\u001b[39mid, hilo\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m---> 35\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Descomponemos los elementos de la respuesta.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DESCRIPTION = \"You are an expert programer in Pyhton. Your specialty is to generate the code responsible for making decisions about actions to be taken in various spacecraft landing environments.The objective is to land the spacecraft within a target zone in the shortest possible time and very gently. A scoring system is used to evaluate the landings, which must be maximized.\"\n",
    "INSTRUCTIONS = f\"\"\"Your task is:\n",
    "1. Analyze and reason about the logs received in the last landing attempts.\n",
    "2. Your goal is to be able to make the correct decision based on what you have learned from the results of previous iterations. You must code the decision making based on your reasoning in a Python function.\n",
    "3. IMPORTANT. Use the following tips in your reasoning to achieve a successful landing:\n",
    "    - First you have to stabilize the falling ship (angle and location), keep falling under control and then land gently at the end.\n",
    "    - It is mandatory to use all the elements of the array of observations received by parameter in your code when deciding what action to take at any given moment. Both position and velocities must be taken into account to know how the ship is doing and towards which states it is heading. All of these must be considered to achieve stability.\n",
    "    - Learn how actions taken affect the future states of the spacecraft in the logs of past events so that you can take this into account when developing code to reach the landing zone.\n",
    "    - The landing zone is in the central area of the x-axis.\n",
    "    - Carefully choose the actions involving the lateral engines according to the rotation of the spacecraft.\n",
    "4. You should analyze the performance that appear in the logs of the code you have generated. You should improve the code generated in the 'act' function in the last iteration without fear of making major changes, seeking to maximize the score received and generate a higher quality code.\n",
    "5. Save the code of the act function in the file 'Action.py' using store_code_in_file function.\n",
    "\"\"\"\n",
    "# 6. Improve your results and correct also any programming error you may have generated in your last code if they exist.\n",
    "NAME = \"Spacecraft Landing Master\"\n",
    "\n",
    "initial_msg = f\"This is the record of an example of a successful landing in this environment, but under other conditions: {success_logs}. You have to be able to learn from it to land successfully with any other conditions. This is the code of the initial function: {agent_initial_code} and these are the execution logs of one landing attempt: {initial_logs}.Take a deep breath and reason step-by-step. After reasoning analyze the results, learn and make better code.\"\n",
    "\n",
    "logger = configura_log('Spacecraft_4o_betterprompt.log')\n",
    "response = create_and_run_llm_loop(initial_msg, logger, model=\"gpt-4o\", num_iterations=5)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de cambio grande en el prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 20:14:46,206 - INFO - HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 20:14:46,436 - INFO - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 20:14:46,707 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_kKFeZP90ZudtrqLAYMtmFMh9/messages \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 20:14:46,886 - INFO - Iteration: 1\n",
      "2024-06-25 20:14:47,337 - INFO - HTTP Request: POST https://api.openai.com/v1/threads/thread_kKFeZP90ZudtrqLAYMtmFMh9/runs \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 20:14:47,558 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_kKFeZP90ZudtrqLAYMtmFMh9/runs/run_QzAvvzyasOb0M35VCpURl38A \"HTTP/1.1 200 OK\"\n",
      "2024-06-25 20:14:47,563 - INFO - Status: queued\n",
      "2024-06-25 20:14:47,793 - INFO - HTTP Request: GET https://api.openai.com/v1/threads/thread_kKFeZP90ZudtrqLAYMtmFMh9/runs/run_QzAvvzyasOb0M35VCpURl38A \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m initial_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the record of an example of a successful landing in this environment, but under other conditions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuccess_logs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is the code of the initial function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_initial_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and these are the execution logs of one landing attempt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_logs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.Before coding take a deep breath and reason step-by-step.What does each value and each change in the observations mean? What effects does each action have on the current state observations? What are the steps to follow to achieve a successful landing?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m logger \u001b[38;5;241m=\u001b[39m configura_log(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpacecraft_4o_Stepback.log\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m response \u001b[38;5;241m=\u001b[39m create_and_run_llm_loop(initial_msg, logger, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[1;32mIn[13], line 35\u001b[0m, in \u001b[0;36mcreate_and_run_llm_loop\u001b[1;34m(Incial_msg, logger, model, num_iterations)\u001b[0m\n\u001b[0;32m     33\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mejecucion\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m     response \u001b[38;5;241m=\u001b[39m agente\u001b[38;5;241m.\u001b[39mget_run(ejecucion\u001b[38;5;241m.\u001b[39mid, hilo\u001b[38;5;241m.\u001b[39mid)\n\u001b[1;32m---> 35\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Descomponemos los elementos de la respuesta.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DESCRIPTION = \"You are an expert spacecraft landing agent. Your specialty is to take the appropriate action at each instant of time based on the environment and state of the spacecraft. To achieve this, you put your knowledge base and the knowledge you acquire by analyzing each execution into a python function in charge of directing the landing.\"\n",
    "INSTRUCTIONS = f\"\"\"To complete the task you must follow the following steps and indications:\n",
    "1. Analyze and reason about the records received in the last landing attempts to learn how the spacecraft behaves in the environment. Keep in mind that conditions may vary.\n",
    "2. To measure how good a landing is, a scoring system that appears in the logs is used, your role is to maximize it. To do so, keep the following in mind:\n",
    "    - Increases/decreases the closer/further the spacecraft is from the landing area (both axes).\n",
    "    - Increased/decreased the slower/faster the spacecraft is moving.\n",
    "    - Decreased the more the spacecraft is tilted.\n",
    "    - Decreased by 0.03 points each frame a side engine is firing and 0.3 points for the center engine.\n",
    "    - Receive 100 points for a successful landing and lose them for crashing.\n",
    "3. IMPORTANT. Use the following tips in your reasoning to achieve a successful landing:\n",
    "    - First you have to stabilize the falling ship (speed, angle and location), keep falling under control and then land gently at the end.\n",
    "    - Use all the elements of the vector of observations, all are relevant to make the right decision.\n",
    "    - Pay close attention to successful events.\n",
    "    - Environment and ship conditions may change but your code must be effective for all cases.\n",
    "    - Find a balance in your landing policy to maximize your score (must exceed 200 points).\n",
    "    - If you are rotating to the left (negative values), you should fire the left engine and vice versa. But always prioritizing a controlled speed with the main engine.\n",
    "4. Add your decision code to the 'act' method and locate errors in it if the landing is unsuccessful.\n",
    "5. Save the code of the act function in the file 'Action.py' using store_code_in_file function.\n",
    "\"\"\"\n",
    "\n",
    "# 6. Improve your results and correct also any programming error you may have generated in your last code if they exist.\n",
    "NAME = \"Spacecraft Landing Master\"\n",
    "\n",
    "initial_msg = f\"This is the record of an example of a successful landing in this environment, but under other conditions: {success_logs}. This is the code of the initial function: {agent_initial_code} and these are the execution logs of one landing attempt: {initial_logs}.Before coding take a deep breath and reason step-by-step.What does each value and each change in the observations mean? What effects does each action have on the current state observations? What are the steps to follow to achieve a successful landing?\"\n",
    "\n",
    "logger = configura_log('Spacecraft_4o_Stepback.log')\n",
    "response = create_and_run_llm_loop(initial_msg, logger, model=\"gpt-3.5-turbo\", num_iterations=5)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a step back.\n",
    "Abstraer primero el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incluir supervisor encargado del stepback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializar_agente(model, msg, description, instructions, name, tools):\n",
    "    \"\"\" Inicializa un agente con un asistente y un hilo.\n",
    "    \n",
    "    Args:\n",
    "        model: str: el modelo de lenguaje a utilizar\n",
    "        msg: str: el mensaje inicial del hilo\n",
    "        \n",
    "    Returns:\n",
    "        agente: AssistantOpenAI: el agente inicializado\n",
    "        asistente: dict: el asistente creado\n",
    "        hilo: dict: el hilo creado\n",
    "    \"\"\"\n",
    "    \n",
    "    agente = AssistantOpenAI(ARCLABKEY_OPENAI)\n",
    "    # Crea un asistente\n",
    "    asistente = agente.create_assistant(model=model, description=description, instructions=instructions, name=name, tools=tools)\n",
    "    # Crea un hilo\n",
    "    hilo = agente.create_thread()\n",
    "    # Añade un mensaje inicial al hilo.\n",
    "    msg = agente.add_message(hilo.id, role=\"user\", content=msg)\n",
    "    \n",
    "    return agente, asistente, hilo\n",
    "\n",
    "\n",
    "def run_message_assistant(agente, asistente, hilo, tool_choice=\"auto\"):\n",
    "    \"\"\" Ejecuta un mensaje en el asistente.\n",
    "    \n",
    "    Args:\n",
    "        agente: AssistantOpenAI: el agente\n",
    "        asistente: dict: el asistente\n",
    "        hilo: dict: el hilo\n",
    "        tool_choice: str: la elección de herramienta a utilizar\n",
    "        \n",
    "    Returns:\n",
    "        ejecucion: dict: la ejecución del mensaje\n",
    "        response: dict: la respuesta del asistente\n",
    "    \"\"\"\n",
    "    # Ejecuta el hilo\n",
    "    ejecucion = agente.run(hilo.id, asistente.id)\n",
    "    response = agente.get_run(ejecucion.id, hilo.id)\n",
    "\n",
    "            # Esperamos a que la respuesta esté lista.\n",
    "    while response.status not in [\"completed\", \"failed\", \"requires_action\"]:\n",
    "        logger.info(f\"Status: {ejecucion.status}\")\n",
    "        response = agente.get_run(ejecucion.id, hilo.id)\n",
    "        time.sleep(20)\n",
    "    return ejecucion, response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback, importlib\n",
    "import Action\n",
    "\n",
    "Action = importlib.reload(Action)\n",
    "\n",
    "def create_and_run_llm_loop(Incial_msg, logger, model=\"gpt-3.5-turbo\", num_iterations=5):\n",
    "    \n",
    "    # Creamos el asistente.\n",
    "    agente, asistente, hilo = inicializar_agente(model, Incial_msg, DESCRIPTION, INSTRUCTIONS, NAME, TOOLS)\n",
    "    \n",
    "    # Primero ejecutamos el razonamiento de STEP BACK.\n",
    "    ejecucion, response = run_message_assistant(agent, asistente, hilo, tool_choice='none')\n",
    "    \n",
    "    print(response)\n",
    "    \n",
    "    # Ahora generamos el código tras el razonamiento.\n",
    "    ejecucion, response = run_message_assistant(agent, asistente, hilo, tool_choice='required')\n",
    "    \n",
    "    \n",
    "    # Bucle de aprendizaje del asistente.\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        logger.info(f\"Iteration: {i+1}\")\n",
    "        compiled = False\n",
    "\n",
    "        # Si en la presente iteración no se ha compilado el código, se pide al asistente corregir los errores antes de iterar.\n",
    "        while not compiled:\n",
    "\n",
    "            # Descomponemos los elementos de la respuesta.\n",
    "            logger.info(f\"Status: {response.status}\")\n",
    "            if response.status == \"completed\":\n",
    "                return response\n",
    "            tool_call = response.required_action.submit_tool_outputs.tool_calls\n",
    "            print(f\"Tool call: {tool_call}\")\n",
    "\n",
    "            # Convierte el string a un diccionario\n",
    "            code_dict = json.loads(tool_call[0].function.arguments)\n",
    "            logger.info(f\"Arguments: {code_dict}\")\n",
    "            \n",
    "            # Obtén el código Python de la llamada a la herramienta\n",
    "            code = code_dict[\"code\"]\n",
    "            filename = code_dict[\"filename\"]  \n",
    "\n",
    "            logger.info(f\"\\nCodigo generado:\\n{code}\")\n",
    "\n",
    "            # Ejecuta el código Python\n",
    "            try:\n",
    "                store_code_in_file(code, filename)\n",
    "                time.sleep(1) # Pequeño retraso para que el sistema operativo pueda reflejar los cambios en el archivo\n",
    "                \n",
    "                # Hacemos commit de los cambios en el repositorio para analizar las modificaciones del agente.\n",
    "                commit_changes(r\"C:\\Users\\adria\\Repos\\TFM__LLM_landing_self-refinement\", f\"4o. Iteración {i+1}.\") \n",
    "                \n",
    "                importlib.reload(Action) # Recargamos el módulo de acciones para que se actualice con las modificaciones del agente.\n",
    "\n",
    "                # Ejecutamos el código generado.\n",
    "                logs = lunar_lander(n_games=1, display=True, recoder=True, video_filename=f\"video/iteration_{i+1}.mp4\")\n",
    "                \n",
    "                # Devolvemos la respuesta al asistente.\n",
    "                for call in tool_call:\n",
    "                    agente.devolver_respuesta(response.id, hilo.id, tool_outputs=[{\"tool_call_id\": call.id, \"output\": \"Run successful.\"}])            \n",
    "                compiled = True\n",
    "                logger.info(f\"Compilación exitosa.\")\n",
    "                \n",
    "                # Esperamos a que el agente esté listo para recibir mensajes y le añadimos el resultado de la iteración.\n",
    "                while response.status not in [\"completed\", \"failed\", \"expired\"]:\n",
    "                    logger.info(f\"Status: {response.status}\")\n",
    "                    response = agente.get_run(response.id, hilo.id)\n",
    "                    time.sleep(20)\n",
    "                \n",
    "                msg = f\"\"\"These are the logs generated by your last code: {logs}. Analyze the performance of the spacecraft and how it differs from the desired result. Be guided by the scoring system. Identify the cause of errors in your code and modify it without fear of making major changes. Think deeply about the priorities of your code and how to order and combine them correctly to achieve success.\"\"\"\n",
    "                logger.info(msg)    \n",
    "                agente.add_message(hilo.id, role=\"user\", content=msg)\n",
    "            \n",
    "            # Alimentamos el asistente con el error generado en la ejecución del código.    \n",
    "            except Exception as e:\n",
    "                logger.exception(\"Error: %s\", e)\n",
    "                error_trace = traceback.format_exc()\n",
    "                for call in tool_call:\n",
    "                    agente.devolver_respuesta(response.id, hilo.id, tool_outputs=[{\"tool_call_id\": call.id, \"output\": \"ERROR.\"}]) \n",
    "                logger.error(f\"Error: {e}.\")\n",
    "                while response.status not in [\"completed\", \"failed\", \"expired\"]:\n",
    "                    logger.info(f\"Status: {response.status}\")\n",
    "                    response = agente.get_run(ejecucion.id, hilo.id)\n",
    "                    time.sleep(30)\n",
    "                msg = f\"The code generated has an error. Please, try again. Error: {e}. Trace: {error_trace}\"   \n",
    "                logger.error(msg)   \n",
    "                agente.add_message(hilo.id, role=\"assistant\", content=msg)\n",
    "    \n",
    "    agente.mostrar_mensajes(hilo.id)  \n",
    "    vaciar_agente(agente)\n",
    "    \n",
    "    logger.info(\"\\nEjecución finalizada.\\n\\n\")       \n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def vaciar_agente(agente):\n",
    "    for assistant in agente.assistants:\n",
    "        agente.delete_assistant(assistant)\n",
    "\n",
    "    for thread in agente.threads:\n",
    "        agente.delete_thread(thread)\n",
    "        \n",
    "    print(\"Asistente vaciado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'success_logs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 36\u001b[0m\n\u001b[0;32m     24\u001b[0m INSTRUCTIONS_SUP \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mTo complete the task you must follow the following steps and indications:\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m1. Analiza como afectan las acciones en el estado del entorno y cuales son las mejores para conseguir un aterrizaje exitoso en cada caso. Analiza que errores se comenten en las ejecuciones y a que parte del código se deben.\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m2. To measure how good a landing is, a scoring system that appears in the logs is used, your role is to maximize it. To do so, keep the following in mind:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m3. You must convey what you have learned so that the agent is able to correct his decision making code and the landing is successful.\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     34\u001b[0m NAME_SUP \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpacecraft Landing Supervisor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 36\u001b[0m initial_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the record of an example of a successful landing in this environment, but under other conditions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuccess_logs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is the code of the initial function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_initial_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and these are the execution logs of one landing attempt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_logs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Take a deep breath and reason step-by-step.What does each value and each change in the observations mean? What effects does each action have on the current state observations? What are the steps to follow to achieve a successful landing?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'success_logs' is not defined"
     ]
    }
   ],
   "source": [
    "DESCRIPTION = \"You are an expert spacecraft landing agent. Your specialty is to take the appropriate action at each instant of time based on the environment and state of the spacecraft. To achieve this, you put your knowledge base and the knowledge you acquire by analyzing each execution into a python function in charge of directing the landing.\"\n",
    "INSTRUCTIONS = f\"\"\"To complete the task you must follow the following steps and indications:\n",
    "1. Analyze and reason about the records received in the last landing attempts to learn how the spacecraft behaves in the environment. Keep in mind that conditions may vary.\n",
    "2. To measure how good a landing is, a scoring system that appears in the logs is used, your role is to maximize it. To do so, keep the following in mind:\n",
    "    - Increases/decreases the closer/further the spacecraft is from the landing area (both axes).\n",
    "    - Increased/decreased the slower/faster the spacecraft is moving.\n",
    "    - Decreased the more the spacecraft is tilted.\n",
    "    - Decreased by 0.03 points each frame a side engine is firing and 0.3 points for the center engine.\n",
    "    - Receive 100 points for a successful landing and lose them for crashing.\n",
    "3. IMPORTANT. Use the following tips in your reasoning to achieve a successful landing:\n",
    "    - First you have to stabilize the falling ship (speed, angle and location), keep falling under control and then land gently at the end.\n",
    "    - Use all the elements of the vector of observations, all are relevant to make the right decision.\n",
    "    - Pay close attention to successful events.\n",
    "    - Environment and ship conditions may change but your code must be effective for all cases.\n",
    "    - Find a balance in your landing policy to maximize your score (must exceed 200 points).\n",
    "    - If you are rotating to the left (negative values), you should fire the left engine and vice versa. But always prioritizing a controlled speed with the main engine.\n",
    "4. Add your decision code to the 'act' method and locate errors in it if the landing is unsuccessful.\n",
    "5. Save the code of the act function in the file 'Action.py' using store_code_in_file function.\n",
    "\"\"\"\n",
    "# 6. Improve your results and correct also any programming error you may have generated in your last code if they exist.\n",
    "NAME = \"Spacecraft Landing Decision coder\"\n",
    "\n",
    "DESCRIPTION_SUP = \"You are an expert agent in space landing environments. Your mission is to supervise another agent in charge of decision making. To do so, you must analyze the records of other landings and of the landings of the code generated by the agent.\"\n",
    "INSTRUCTIONS_SUP = f\"\"\"To complete the task you must follow the following steps and indications:\n",
    "1. Analiza como afectan las acciones en el estado del entorno y cuales son las mejores para conseguir un aterrizaje exitoso en cada caso. Analiza que errores se comenten en las ejecuciones y a que parte del código se deben.\n",
    "2. To measure how good a landing is, a scoring system that appears in the logs is used, your role is to maximize it. To do so, keep the following in mind:\n",
    "    - Increases/decreases the closer/further the spacecraft is from the landing area (both axes).\n",
    "    - Increased/decreased the slower/faster the spacecraft is moving.\n",
    "    - Decreased the more the spacecraft is tilted.\n",
    "    - Decreased by 0.03 points each frame a side engine is firing and 0.3 points for the center engine.\n",
    "    - Receive 100 points for a successful landing and lose them for crashing.\n",
    "3. You must convey what you have learned so that the agent is able to correct his decision making code and the landing is successful.\n",
    "\"\"\"\n",
    "NAME_SUP = \"Spacecraft Landing Supervisor\"\n",
    "\n",
    "initial_msg = f\"This is the record of an example of a successful landing in this environment, but under other conditions: {success_logs}. This is the code of the initial function: {agent_initial_code} and these are the execution logs of one landing attempt: {initial_logs}. Take a deep breath and reason step-by-step.What does each value and each change in the observations mean? What effects does each action have on the current state observations? What are the steps to follow to achieve a successful landing?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = configura_log('Spacecraft_4o_Stepback.log')\n",
    "response = create_and_run_llm_loop(initial_msg, logger, model=\"gpt-3.5-turbo\", num_iterations=5)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_etNxMQZZRe1n0Xgz8bX9hIY8', assistant_id='asst_H4IKpdb24RVq3VGYKXZzHMij', cancelled_at=None, completed_at=1719341075, created_at=1719341067, expires_at=None, failed_at=None, incomplete_details=None, instructions='To complete the task you must follow the following steps and indications:\\n1. Analiza como afectan las acciones en el estado del entorno y cuales son las mejores para conseguir un aterrizaje exitoso en cada caso. Analiza que errores se comenten en las ejecuciones y a que parte del código se deben.\\n2. To measure how good a landing is, a scoring system that appears in the logs is used, your role is to maximize it. To do so, keep the following in mind:\\n    - Increases/decreases the closer/further the spacecraft is from the landing area (both axes).\\n    - Increased/decreased the slower/faster the spacecraft is moving.\\n    - Decreased the more the spacecraft is tilted.\\n    - Decreased by 0.03 points each frame a side engine is firing and 0.3 points for the center engine.\\n    - Receive 100 points for a successful landing and lose them for crashing.\\n3. You must convey what you have learned so that the agent is able to correct his decision making code and the landing is successful.\\n', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo', object='thread.run', required_action=None, response_format='auto', started_at=1719341067, status='completed', thread_id='thread_3WA7baxJSd8lqwM9YbhhR7Pj', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=366, prompt_tokens=15321, total_tokens=15687), temperature=1.0, top_p=1.0, tool_resources={}, parallel_tool_calls=True)\n"
     ]
    }
   ],
   "source": [
    "agente = AssistantOpenAI(ARCLABKEY_OPENAI)\n",
    "\n",
    "# Crea un asistente\n",
    "asistente = agente.create_assistant(model=\"gpt-3.5-turbo\", description=DESCRIPTION_SUP, instructions=INSTRUCTIONS_SUP, name=NAME_SUP)\n",
    "    \n",
    "# Crea un hilo\n",
    "hilo = agente.create_thread()\n",
    "\n",
    "initial_msg = f\"This is the record of an example of a successful landing in this environment, but under other conditions: {success_logs}. This is the code of the initial function: {agent_initial_code} and these are the execution logs of one landing attempt: {initial_logs}.Before coding take a deep breath and reason step-by-step.What does each value and each change in the observations mean? What effects does each action have on the current state observations? What are the steps to follow to achieve a successful landing?\"\n",
    "    \n",
    "# Añade un mensaje inicial al hilo.\n",
    "msg = agente.add_message(hilo.id, role=\"user\", content=initial_msg)\n",
    "\n",
    "\n",
    "# Ejecuta el hilo\n",
    "ejecucion = agente.run(hilo.id, asistente.id)\n",
    "response = agente.get_run(ejecucion.id, hilo.id)\n",
    "\n",
    "# Esperamos a que la respuesta esté lista.\n",
    "while response.status not in [\"completed\", \"failed\", \"requires_action\"]:\n",
    "    #logger.info(f\"Status: {ejecucion.status}\")\n",
    "    response = agente.get_run(ejecucion.id, hilo.id)\n",
    "    time.sleep(20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "- Corregir rotación.\n",
    "- Cantidad de logs.\n",
    "- Partir de ejemplo exitoso para afinarlo. (y generalizar)\n",
    "- Incluir take step back.\n",
    "- Probar con 2 modelos. Uno encargado del razonamiento y otro de codificar. (O uno que retroalimente al otro con las conclusiones obtenidas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
